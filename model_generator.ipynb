{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation_models\n",
      "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
      "Collecting efficientnet==1.0.0\n",
      "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
      "Collecting image-classifiers==1.0.0\n",
      "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.23.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.7.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2022.5.4)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.4)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.19.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.8.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.9)\n",
      "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation_models\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation_models-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting albumentations\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.23.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2.8.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2022.5.4)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2.19.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.1 opencv-python-headless-4.8.0.74 qudida-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install segmentation_models\n",
    "! pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "# Model stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.utils import normalize\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import model_utility\n",
    "import os\n",
    "\n",
    "#path sorting\n",
    "import glob\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "#math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/\"\n",
    "type = \"both2Aug\"\n",
    "training_size = \"1200\"\n",
    "epoch_num = \"1400\"\n",
    "backbone = \"resnet34\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose([\n",
      "  ShiftScaleRotate(always_apply=False, p=1, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(0, 0), scale_limit=(0.0, 0.0), rotate_limit=(0, 0), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box'),\n",
      "  RandomBrightnessContrast(always_apply=True, p=1, brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), brightness_by_max=True),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={'image': 'mask'}, is_check_shapes=True)\n",
      "1200 1200\n"
     ]
    }
   ],
   "source": [
    "# X, Y = [], []\n",
    "\n",
    "X, Y = model_utility.data_gather(X, Y, \"dark_spokes_training_images\", \"dark_spokes_training_masks\", aug_flag = 1, aug_num = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 160, 736)\n",
      "(180, 160, 736)\n",
      "(1020, 160, 736)\n",
      "(180, 160, 736)\n"
     ]
    }
   ],
   "source": [
    "X = normalize(np.array(X), axis=1)\n",
    "Y = (np.array(Y))/255.\n",
    "\n",
    "# train/test split test_size = .15 for light, .25 for dark(no agu)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.15, random_state = 42)\n",
    "\n",
    "SIZE_Y, SIZE_X = X.shape[1], X.shape[2]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data (InputLayer)              [(None, 160, 736, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " bn_data (BatchNormalization)   (None, 160, 736, 1)  3           ['data[0][0]']                   \n",
      "                                                                                                  \n",
      " zero_padding2d_34 (ZeroPadding  (None, 166, 742, 1)  0          ['bn_data[0][0]']                \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv0 (Conv2D)                 (None, 80, 368, 64)  3136        ['zero_padding2d_34[0][0]']      \n",
      "                                                                                                  \n",
      " bn0 (BatchNormalization)       (None, 80, 368, 64)  256         ['conv0[0][0]']                  \n",
      "                                                                                                  \n",
      " relu0 (Activation)             (None, 80, 368, 64)  0           ['bn0[0][0]']                    \n",
      "                                                                                                  \n",
      " zero_padding2d_35 (ZeroPadding  (None, 82, 370, 64)  0          ['relu0[0][0]']                  \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " pooling0 (MaxPooling2D)        (None, 40, 184, 64)  0           ['zero_padding2d_35[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_bn1 (BatchNormali  (None, 40, 184, 64)  256        ['pooling0[0][0]']               \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu1 (Activation  (None, 40, 184, 64)  0          ['stage1_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_36 (ZeroPadding  (None, 42, 186, 64)  0          ['stage1_unit1_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit1_conv1 (Conv2D)    (None, 40, 184, 64)  36864       ['zero_padding2d_36[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_bn2 (BatchNormali  (None, 40, 184, 64)  256        ['stage1_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit1_relu2 (Activation  (None, 40, 184, 64)  0          ['stage1_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_37 (ZeroPadding  (None, 42, 186, 64)  0          ['stage1_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit1_conv2 (Conv2D)    (None, 40, 184, 64)  36864       ['zero_padding2d_37[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit1_sc (Conv2D)       (None, 40, 184, 64)  4096        ['stage1_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 40, 184, 64)  0           ['stage1_unit1_conv2[0][0]',     \n",
      "                                                                  'stage1_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage1_unit2_bn1 (BatchNormali  (None, 40, 184, 64)  256        ['add_16[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu1 (Activation  (None, 40, 184, 64)  0          ['stage1_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_38 (ZeroPadding  (None, 42, 186, 64)  0          ['stage1_unit2_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit2_conv1 (Conv2D)    (None, 40, 184, 64)  36864       ['zero_padding2d_38[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit2_bn2 (BatchNormali  (None, 40, 184, 64)  256        ['stage1_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit2_relu2 (Activation  (None, 40, 184, 64)  0          ['stage1_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_39 (ZeroPadding  (None, 42, 186, 64)  0          ['stage1_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit2_conv2 (Conv2D)    (None, 40, 184, 64)  36864       ['zero_padding2d_39[0][0]']      \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 40, 184, 64)  0           ['stage1_unit2_conv2[0][0]',     \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " stage1_unit3_bn1 (BatchNormali  (None, 40, 184, 64)  256        ['add_17[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu1 (Activation  (None, 40, 184, 64)  0          ['stage1_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_40 (ZeroPadding  (None, 42, 186, 64)  0          ['stage1_unit3_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit3_conv1 (Conv2D)    (None, 40, 184, 64)  36864       ['zero_padding2d_40[0][0]']      \n",
      "                                                                                                  \n",
      " stage1_unit3_bn2 (BatchNormali  (None, 40, 184, 64)  256        ['stage1_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage1_unit3_relu2 (Activation  (None, 40, 184, 64)  0          ['stage1_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_41 (ZeroPadding  (None, 42, 186, 64)  0          ['stage1_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage1_unit3_conv2 (Conv2D)    (None, 40, 184, 64)  36864       ['zero_padding2d_41[0][0]']      \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 40, 184, 64)  0           ['stage1_unit3_conv2[0][0]',     \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit1_bn1 (BatchNormali  (None, 40, 184, 64)  256        ['add_18[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu1 (Activation  (None, 40, 184, 64)  0          ['stage2_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_42 (ZeroPadding  (None, 42, 186, 64)  0          ['stage2_unit1_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit1_conv1 (Conv2D)    (None, 20, 92, 128)  73728       ['zero_padding2d_42[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit1_bn2 (BatchNormali  (None, 20, 92, 128)  512        ['stage2_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit1_relu2 (Activation  (None, 20, 92, 128)  0          ['stage2_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_43 (ZeroPadding  (None, 22, 94, 128)  0          ['stage2_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit1_conv2 (Conv2D)    (None, 20, 92, 128)  147456      ['zero_padding2d_43[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit1_sc (Conv2D)       (None, 20, 92, 128)  8192        ['stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 20, 92, 128)  0           ['stage2_unit1_conv2[0][0]',     \n",
      "                                                                  'stage2_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage2_unit2_bn1 (BatchNormali  (None, 20, 92, 128)  512        ['add_19[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu1 (Activation  (None, 20, 92, 128)  0          ['stage2_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_44 (ZeroPadding  (None, 22, 94, 128)  0          ['stage2_unit2_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit2_conv1 (Conv2D)    (None, 20, 92, 128)  147456      ['zero_padding2d_44[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit2_bn2 (BatchNormali  (None, 20, 92, 128)  512        ['stage2_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit2_relu2 (Activation  (None, 20, 92, 128)  0          ['stage2_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_45 (ZeroPadding  (None, 22, 94, 128)  0          ['stage2_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit2_conv2 (Conv2D)    (None, 20, 92, 128)  147456      ['zero_padding2d_45[0][0]']      \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 20, 92, 128)  0           ['stage2_unit2_conv2[0][0]',     \n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit3_bn1 (BatchNormali  (None, 20, 92, 128)  512        ['add_20[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu1 (Activation  (None, 20, 92, 128)  0          ['stage2_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_46 (ZeroPadding  (None, 22, 94, 128)  0          ['stage2_unit3_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit3_conv1 (Conv2D)    (None, 20, 92, 128)  147456      ['zero_padding2d_46[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit3_bn2 (BatchNormali  (None, 20, 92, 128)  512        ['stage2_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit3_relu2 (Activation  (None, 20, 92, 128)  0          ['stage2_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_47 (ZeroPadding  (None, 22, 94, 128)  0          ['stage2_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit3_conv2 (Conv2D)    (None, 20, 92, 128)  147456      ['zero_padding2d_47[0][0]']      \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 20, 92, 128)  0           ['stage2_unit3_conv2[0][0]',     \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " stage2_unit4_bn1 (BatchNormali  (None, 20, 92, 128)  512        ['add_21[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu1 (Activation  (None, 20, 92, 128)  0          ['stage2_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_48 (ZeroPadding  (None, 22, 94, 128)  0          ['stage2_unit4_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit4_conv1 (Conv2D)    (None, 20, 92, 128)  147456      ['zero_padding2d_48[0][0]']      \n",
      "                                                                                                  \n",
      " stage2_unit4_bn2 (BatchNormali  (None, 20, 92, 128)  512        ['stage2_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage2_unit4_relu2 (Activation  (None, 20, 92, 128)  0          ['stage2_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_49 (ZeroPadding  (None, 22, 94, 128)  0          ['stage2_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage2_unit4_conv2 (Conv2D)    (None, 20, 92, 128)  147456      ['zero_padding2d_49[0][0]']      \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 20, 92, 128)  0           ['stage2_unit4_conv2[0][0]',     \n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit1_bn1 (BatchNormali  (None, 20, 92, 128)  512        ['add_22[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu1 (Activation  (None, 20, 92, 128)  0          ['stage3_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_50 (ZeroPadding  (None, 22, 94, 128)  0          ['stage3_unit1_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit1_conv1 (Conv2D)    (None, 10, 46, 256)  294912      ['zero_padding2d_50[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit1_bn2 (BatchNormali  (None, 10, 46, 256)  1024       ['stage3_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit1_relu2 (Activation  (None, 10, 46, 256)  0          ['stage3_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_51 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit1_conv2 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_51[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit1_sc (Conv2D)       (None, 10, 46, 256)  32768       ['stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 10, 46, 256)  0           ['stage3_unit1_conv2[0][0]',     \n",
      "                                                                  'stage3_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage3_unit2_bn1 (BatchNormali  (None, 10, 46, 256)  1024       ['add_23[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu1 (Activation  (None, 10, 46, 256)  0          ['stage3_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_52 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit2_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit2_conv1 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_52[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit2_bn2 (BatchNormali  (None, 10, 46, 256)  1024       ['stage3_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit2_relu2 (Activation  (None, 10, 46, 256)  0          ['stage3_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_53 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit2_conv2 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_53[0][0]']      \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 10, 46, 256)  0           ['stage3_unit2_conv2[0][0]',     \n",
      "                                                                  'add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit3_bn1 (BatchNormali  (None, 10, 46, 256)  1024       ['add_24[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu1 (Activation  (None, 10, 46, 256)  0          ['stage3_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_54 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit3_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit3_conv1 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_54[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit3_bn2 (BatchNormali  (None, 10, 46, 256)  1024       ['stage3_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit3_relu2 (Activation  (None, 10, 46, 256)  0          ['stage3_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_55 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit3_conv2 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_55[0][0]']      \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 10, 46, 256)  0           ['stage3_unit3_conv2[0][0]',     \n",
      "                                                                  'add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit4_bn1 (BatchNormali  (None, 10, 46, 256)  1024       ['add_25[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu1 (Activation  (None, 10, 46, 256)  0          ['stage3_unit4_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_56 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit4_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit4_conv1 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_56[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit4_bn2 (BatchNormali  (None, 10, 46, 256)  1024       ['stage3_unit4_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit4_relu2 (Activation  (None, 10, 46, 256)  0          ['stage3_unit4_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_57 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit4_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit4_conv2 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_57[0][0]']      \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 10, 46, 256)  0           ['stage3_unit4_conv2[0][0]',     \n",
      "                                                                  'add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit5_bn1 (BatchNormali  (None, 10, 46, 256)  1024       ['add_26[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu1 (Activation  (None, 10, 46, 256)  0          ['stage3_unit5_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_58 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit5_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit5_conv1 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_58[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit5_bn2 (BatchNormali  (None, 10, 46, 256)  1024       ['stage3_unit5_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit5_relu2 (Activation  (None, 10, 46, 256)  0          ['stage3_unit5_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_59 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit5_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit5_conv2 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_59[0][0]']      \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 10, 46, 256)  0           ['stage3_unit5_conv2[0][0]',     \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " stage3_unit6_bn1 (BatchNormali  (None, 10, 46, 256)  1024       ['add_27[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu1 (Activation  (None, 10, 46, 256)  0          ['stage3_unit6_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_60 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit6_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit6_conv1 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_60[0][0]']      \n",
      "                                                                                                  \n",
      " stage3_unit6_bn2 (BatchNormali  (None, 10, 46, 256)  1024       ['stage3_unit6_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage3_unit6_relu2 (Activation  (None, 10, 46, 256)  0          ['stage3_unit6_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_61 (ZeroPadding  (None, 12, 48, 256)  0          ['stage3_unit6_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage3_unit6_conv2 (Conv2D)    (None, 10, 46, 256)  589824      ['zero_padding2d_61[0][0]']      \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 10, 46, 256)  0           ['stage3_unit6_conv2[0][0]',     \n",
      "                                                                  'add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit1_bn1 (BatchNormali  (None, 10, 46, 256)  1024       ['add_28[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu1 (Activation  (None, 10, 46, 256)  0          ['stage4_unit1_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_62 (ZeroPadding  (None, 12, 48, 256)  0          ['stage4_unit1_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit1_conv1 (Conv2D)    (None, 5, 23, 512)   1179648     ['zero_padding2d_62[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit1_bn2 (BatchNormali  (None, 5, 23, 512)  2048        ['stage4_unit1_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit1_relu2 (Activation  (None, 5, 23, 512)  0           ['stage4_unit1_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_63 (ZeroPadding  (None, 7, 25, 512)  0           ['stage4_unit1_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit1_conv2 (Conv2D)    (None, 5, 23, 512)   2359296     ['zero_padding2d_63[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit1_sc (Conv2D)       (None, 5, 23, 512)   131072      ['stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 5, 23, 512)   0           ['stage4_unit1_conv2[0][0]',     \n",
      "                                                                  'stage4_unit1_sc[0][0]']        \n",
      "                                                                                                  \n",
      " stage4_unit2_bn1 (BatchNormali  (None, 5, 23, 512)  2048        ['add_29[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu1 (Activation  (None, 5, 23, 512)  0           ['stage4_unit2_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_64 (ZeroPadding  (None, 7, 25, 512)  0           ['stage4_unit2_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit2_conv1 (Conv2D)    (None, 5, 23, 512)   2359296     ['zero_padding2d_64[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit2_bn2 (BatchNormali  (None, 5, 23, 512)  2048        ['stage4_unit2_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit2_relu2 (Activation  (None, 5, 23, 512)  0           ['stage4_unit2_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_65 (ZeroPadding  (None, 7, 25, 512)  0           ['stage4_unit2_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit2_conv2 (Conv2D)    (None, 5, 23, 512)   2359296     ['zero_padding2d_65[0][0]']      \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 5, 23, 512)   0           ['stage4_unit2_conv2[0][0]',     \n",
      "                                                                  'add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " stage4_unit3_bn1 (BatchNormali  (None, 5, 23, 512)  2048        ['add_30[0][0]']                 \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu1 (Activation  (None, 5, 23, 512)  0           ['stage4_unit3_bn1[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_66 (ZeroPadding  (None, 7, 25, 512)  0           ['stage4_unit3_relu1[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit3_conv1 (Conv2D)    (None, 5, 23, 512)   2359296     ['zero_padding2d_66[0][0]']      \n",
      "                                                                                                  \n",
      " stage4_unit3_bn2 (BatchNormali  (None, 5, 23, 512)  2048        ['stage4_unit3_conv1[0][0]']     \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " stage4_unit3_relu2 (Activation  (None, 5, 23, 512)  0           ['stage4_unit3_bn2[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_67 (ZeroPadding  (None, 7, 25, 512)  0           ['stage4_unit3_relu2[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stage4_unit3_conv2 (Conv2D)    (None, 5, 23, 512)   2359296     ['zero_padding2d_67[0][0]']      \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 5, 23, 512)   0           ['stage4_unit3_conv2[0][0]',     \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 5, 23, 512)   2048        ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " relu1 (Activation)             (None, 5, 23, 512)   0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " decoder_stage0_upsampling (UpS  (None, 10, 46, 512)  0          ['relu1[0][0]']                  \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage0_concat (Concate  (None, 10, 46, 768)  0          ['decoder_stage0_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'stage4_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage0a_conv (Conv2D)  (None, 10, 46, 256)  1769472     ['decoder_stage0_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage0a_bn (BatchNorma  (None, 10, 46, 256)  1024       ['decoder_stage0a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0a_relu (Activati  (None, 10, 46, 256)  0          ['decoder_stage0a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0b_conv (Conv2D)  (None, 10, 46, 256)  589824      ['decoder_stage0a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage0b_bn (BatchNorma  (None, 10, 46, 256)  1024       ['decoder_stage0b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0b_relu (Activati  (None, 10, 46, 256)  0          ['decoder_stage0b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1_upsampling (UpS  (None, 20, 92, 256)  0          ['decoder_stage0b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage1_concat (Concate  (None, 20, 92, 384)  0          ['decoder_stage1_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'stage3_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage1a_conv (Conv2D)  (None, 20, 92, 128)  442368      ['decoder_stage1_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage1a_bn (BatchNorma  (None, 20, 92, 128)  512        ['decoder_stage1a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1a_relu (Activati  (None, 20, 92, 128)  0          ['decoder_stage1a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1b_conv (Conv2D)  (None, 20, 92, 128)  147456      ['decoder_stage1a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage1b_bn (BatchNorma  (None, 20, 92, 128)  512        ['decoder_stage1b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1b_relu (Activati  (None, 20, 92, 128)  0          ['decoder_stage1b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2_upsampling (UpS  (None, 40, 184, 128  0          ['decoder_stage1b_relu[0][0]']   \n",
      " ampling2D)                     )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage2_concat (Concate  (None, 40, 184, 192  0          ['decoder_stage2_upsampling[0][0]\n",
      " nate)                          )                                ',                               \n",
      "                                                                  'stage2_unit1_relu1[0][0]']     \n",
      "                                                                                                  \n",
      " decoder_stage2a_conv (Conv2D)  (None, 40, 184, 64)  110592      ['decoder_stage2_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage2a_bn (BatchNorma  (None, 40, 184, 64)  256        ['decoder_stage2a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2a_relu (Activati  (None, 40, 184, 64)  0          ['decoder_stage2a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2b_conv (Conv2D)  (None, 40, 184, 64)  36864       ['decoder_stage2a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage2b_bn (BatchNorma  (None, 40, 184, 64)  256        ['decoder_stage2b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2b_relu (Activati  (None, 40, 184, 64)  0          ['decoder_stage2b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3_upsampling (UpS  (None, 80, 368, 64)  0          ['decoder_stage2b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage3_concat (Concate  (None, 80, 368, 128  0          ['decoder_stage3_upsampling[0][0]\n",
      " nate)                          )                                ',                               \n",
      "                                                                  'relu0[0][0]']                  \n",
      "                                                                                                  \n",
      " decoder_stage3a_conv (Conv2D)  (None, 80, 368, 32)  36864       ['decoder_stage3_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage3a_bn (BatchNorma  (None, 80, 368, 32)  128        ['decoder_stage3a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage3a_relu (Activati  (None, 80, 368, 32)  0          ['decoder_stage3a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3b_conv (Conv2D)  (None, 80, 368, 32)  9216        ['decoder_stage3a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage3b_bn (BatchNorma  (None, 80, 368, 32)  128        ['decoder_stage3b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage3b_relu (Activati  (None, 80, 368, 32)  0          ['decoder_stage3b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage4_upsampling (UpS  (None, 160, 736, 32  0          ['decoder_stage3b_relu[0][0]']   \n",
      " ampling2D)                     )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_conv (Conv2D)  (None, 160, 736, 16  4608        ['decoder_stage4_upsampling[0][0]\n",
      "                                )                                ']                               \n",
      "                                                                                                  \n",
      " decoder_stage4a_bn (BatchNorma  (None, 160, 736, 16  64         ['decoder_stage4a_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_relu (Activati  (None, 160, 736, 16  0          ['decoder_stage4a_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_conv (Conv2D)  (None, 160, 736, 16  2304        ['decoder_stage4a_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_bn (BatchNorma  (None, 160, 736, 16  64         ['decoder_stage4b_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_relu (Activati  (None, 160, 736, 16  0          ['decoder_stage4b_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " final_conv (Conv2D)            (None, 160, 736, 1)  145         ['decoder_stage4b_relu[0][0]']   \n",
      "                                                                                                  \n",
      " sigmoid (Activation)           (None, 160, 736, 1)  0           ['final_conv[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,449,876\n",
      "Trainable params: 24,432,530\n",
      "Non-trainable params: 17,346\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = model_utility.define_model(SIZE_Y, SIZE_X, backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1400\n",
      "89/89 [==============================] - 29s 260ms/step - loss: 0.2359 - iou_score: 0.0563 - val_loss: 0.1693 - val_iou_score: 0.0092\n",
      "Epoch 2/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0719 - iou_score: 0.1397 - val_loss: 0.1582 - val_iou_score: 0.0306\n",
      "Epoch 3/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0524 - iou_score: 0.2366 - val_loss: 0.1128 - val_iou_score: 0.0021\n",
      "Epoch 4/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0418 - iou_score: 0.3235 - val_loss: 0.0840 - val_iou_score: 0.0182\n",
      "Epoch 5/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0358 - iou_score: 0.3774 - val_loss: 0.0843 - val_iou_score: 0.0213\n",
      "Epoch 6/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0316 - iou_score: 0.4226 - val_loss: 0.0998 - val_iou_score: 0.0062\n",
      "Epoch 7/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0302 - iou_score: 0.4316 - val_loss: 0.0945 - val_iou_score: 0.0475\n",
      "Epoch 8/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 0.0316 - iou_score: 0.4268 - val_loss: 0.1204 - val_iou_score: 0.0061\n",
      "Epoch 9/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0301 - iou_score: 0.4465 - val_loss: 0.0908 - val_iou_score: 0.0871\n",
      "Epoch 10/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0293 - iou_score: 0.4458 - val_loss: 0.0330 - val_iou_score: 0.3259\n",
      "Epoch 11/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0252 - iou_score: 0.5022 - val_loss: 0.0354 - val_iou_score: 0.3242\n",
      "Epoch 12/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0252 - iou_score: 0.4948 - val_loss: 0.0280 - val_iou_score: 0.4045\n",
      "Epoch 13/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0227 - iou_score: 0.5324 - val_loss: 0.0213 - val_iou_score: 0.4499\n",
      "Epoch 14/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0209 - iou_score: 0.5594 - val_loss: 0.0211 - val_iou_score: 0.4685\n",
      "Epoch 15/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0198 - iou_score: 0.5667 - val_loss: 0.0212 - val_iou_score: 0.5017\n",
      "Epoch 16/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0213 - iou_score: 0.5577 - val_loss: 0.0253 - val_iou_score: 0.4575\n",
      "Epoch 17/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0206 - iou_score: 0.5671 - val_loss: 0.0209 - val_iou_score: 0.4767\n",
      "Epoch 18/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0168 - iou_score: 0.6230 - val_loss: 0.0158 - val_iou_score: 0.5326\n",
      "Epoch 19/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0164 - iou_score: 0.6266 - val_loss: 0.0185 - val_iou_score: 0.5305\n",
      "Epoch 20/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0169 - iou_score: 0.6176 - val_loss: 0.0155 - val_iou_score: 0.5627\n",
      "Epoch 21/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0149 - iou_score: 0.6528 - val_loss: 0.0172 - val_iou_score: 0.5373\n",
      "Epoch 22/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0141 - iou_score: 0.6618 - val_loss: 0.0132 - val_iou_score: 0.5915\n",
      "Epoch 23/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0142 - iou_score: 0.6624 - val_loss: 0.0177 - val_iou_score: 0.5628\n",
      "Epoch 24/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0135 - iou_score: 0.6783 - val_loss: 0.0132 - val_iou_score: 0.6076\n",
      "Epoch 25/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0147 - iou_score: 0.6641 - val_loss: 0.0227 - val_iou_score: 0.4883\n",
      "Epoch 26/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0141 - iou_score: 0.6660 - val_loss: 0.0130 - val_iou_score: 0.5950\n",
      "Epoch 27/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0129 - iou_score: 0.6939 - val_loss: 0.0123 - val_iou_score: 0.6061\n",
      "Epoch 28/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0114 - iou_score: 0.7168 - val_loss: 0.0121 - val_iou_score: 0.6088\n",
      "Epoch 29/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0103 - iou_score: 0.7388 - val_loss: 0.0100 - val_iou_score: 0.6573\n",
      "Epoch 30/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0119 - iou_score: 0.7073 - val_loss: 0.0122 - val_iou_score: 0.6293\n",
      "Epoch 31/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 0.0102 - iou_score: 0.7429 - val_loss: 0.0113 - val_iou_score: 0.6427\n",
      "Epoch 32/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 0.0102 - iou_score: 0.7449 - val_loss: 0.0108 - val_iou_score: 0.6444\n",
      "Epoch 33/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 0.0094 - iou_score: 0.7612 - val_loss: 0.0091 - val_iou_score: 0.6850\n",
      "Epoch 34/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 0.0093 - iou_score: 0.7655 - val_loss: 0.0085 - val_iou_score: 0.6877\n",
      "Epoch 35/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0087 - iou_score: 0.7810 - val_loss: 0.0141 - val_iou_score: 0.6593\n",
      "Epoch 36/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0091 - iou_score: 0.7698 - val_loss: 0.0095 - val_iou_score: 0.6807\n",
      "Epoch 37/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0085 - iou_score: 0.7848 - val_loss: 0.0084 - val_iou_score: 0.7093\n",
      "Epoch 38/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0134 - iou_score: 0.6981 - val_loss: 0.0173 - val_iou_score: 0.5685\n",
      "Epoch 39/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0094 - iou_score: 0.7638 - val_loss: 0.0084 - val_iou_score: 0.6941\n",
      "Epoch 40/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0094 - iou_score: 0.7699 - val_loss: 0.0134 - val_iou_score: 0.6326\n",
      "Epoch 41/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0080 - iou_score: 0.7959 - val_loss: 0.0085 - val_iou_score: 0.7000\n",
      "Epoch 42/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0071 - iou_score: 0.8182 - val_loss: 0.0069 - val_iou_score: 0.7343\n",
      "Epoch 43/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0067 - iou_score: 0.8249 - val_loss: 0.0069 - val_iou_score: 0.7344\n",
      "Epoch 44/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0065 - iou_score: 0.8315 - val_loss: 0.0060 - val_iou_score: 0.7515\n",
      "Epoch 45/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0069 - iou_score: 0.8139 - val_loss: 0.0064 - val_iou_score: 0.7537\n",
      "Epoch 46/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0066 - iou_score: 0.8197 - val_loss: 0.0121 - val_iou_score: 0.6549\n",
      "Epoch 47/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 0.0122 - iou_score: 0.7229 - val_loss: 0.0123 - val_iou_score: 0.6405\n",
      "Epoch 48/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0070 - iou_score: 0.8200 - val_loss: 0.0058 - val_iou_score: 0.7548\n",
      "Epoch 49/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0058 - iou_score: 0.8461 - val_loss: 0.0054 - val_iou_score: 0.7660\n",
      "Epoch 50/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0059 - iou_score: 0.8493 - val_loss: 0.0064 - val_iou_score: 0.7542\n",
      "Epoch 51/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0056 - iou_score: 0.8421 - val_loss: 0.0057 - val_iou_score: 0.7702\n",
      "Epoch 52/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0051 - iou_score: 0.8676 - val_loss: 0.0046 - val_iou_score: 0.7922\n",
      "Epoch 53/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0049 - iou_score: 0.8702 - val_loss: 0.0047 - val_iou_score: 0.7979\n",
      "Epoch 54/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0045 - iou_score: 0.8798 - val_loss: 0.0049 - val_iou_score: 0.7881\n",
      "Epoch 55/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0049 - iou_score: 0.8720 - val_loss: 0.0047 - val_iou_score: 0.7974\n",
      "Epoch 56/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0043 - iou_score: 0.8758 - val_loss: 0.0044 - val_iou_score: 0.8024\n",
      "Epoch 57/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0045 - iou_score: 0.8804 - val_loss: 0.0048 - val_iou_score: 0.7973\n",
      "Epoch 58/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0043 - iou_score: 0.8837 - val_loss: 0.0049 - val_iou_score: 0.7950\n",
      "Epoch 59/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0043 - iou_score: 0.8768 - val_loss: 0.0045 - val_iou_score: 0.8036\n",
      "Epoch 60/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0043 - iou_score: 0.8858 - val_loss: 0.0054 - val_iou_score: 0.7914\n",
      "Epoch 61/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0044 - iou_score: 0.8836 - val_loss: 0.0038 - val_iou_score: 0.8174\n",
      "Epoch 62/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 0.0043 - iou_score: 0.8888 - val_loss: 0.0050 - val_iou_score: 0.7974\n",
      "Epoch 63/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0040 - iou_score: 0.8901 - val_loss: 0.0037 - val_iou_score: 0.8162\n",
      "Epoch 64/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 0.0035 - iou_score: 0.9061 - val_loss: 0.0036 - val_iou_score: 0.8236\n",
      "Epoch 65/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0036 - iou_score: 0.9040 - val_loss: 0.0033 - val_iou_score: 0.8343\n",
      "Epoch 66/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0032 - iou_score: 0.9130 - val_loss: 0.0038 - val_iou_score: 0.8251\n",
      "Epoch 67/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0036 - iou_score: 0.9031 - val_loss: 0.0038 - val_iou_score: 0.8224\n",
      "Epoch 68/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0036 - iou_score: 0.9013 - val_loss: 0.0033 - val_iou_score: 0.8316\n",
      "Epoch 69/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0033 - iou_score: 0.9105 - val_loss: 0.0046 - val_iou_score: 0.8180\n",
      "Epoch 70/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0033 - iou_score: 0.9128 - val_loss: 0.0032 - val_iou_score: 0.8365\n",
      "Epoch 71/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0032 - iou_score: 0.9142 - val_loss: 0.0038 - val_iou_score: 0.8242\n",
      "Epoch 72/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0030 - iou_score: 0.9168 - val_loss: 0.0034 - val_iou_score: 0.8369\n",
      "Epoch 73/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0032 - iou_score: 0.9164 - val_loss: 0.0039 - val_iou_score: 0.8256\n",
      "Epoch 74/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0035 - iou_score: 0.9066 - val_loss: 0.0035 - val_iou_score: 0.8346\n",
      "Epoch 75/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0060 - iou_score: 0.8415 - val_loss: 0.0095 - val_iou_score: 0.7352\n",
      "Epoch 76/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0042 - iou_score: 0.8841 - val_loss: 0.0038 - val_iou_score: 0.8182\n",
      "Epoch 77/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0041 - iou_score: 0.8963 - val_loss: 0.0170 - val_iou_score: 0.6428\n",
      "Epoch 78/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0043 - iou_score: 0.8907 - val_loss: 0.0034 - val_iou_score: 0.8285\n",
      "Epoch 79/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0028 - iou_score: 0.9234 - val_loss: 0.0032 - val_iou_score: 0.8395\n",
      "Epoch 80/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0026 - iou_score: 0.9290 - val_loss: 0.0028 - val_iou_score: 0.8469\n",
      "Epoch 81/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0028 - iou_score: 0.9216 - val_loss: 0.0032 - val_iou_score: 0.8404\n",
      "Epoch 82/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0026 - iou_score: 0.9304 - val_loss: 0.0032 - val_iou_score: 0.8451\n",
      "Epoch 83/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0027 - iou_score: 0.9281 - val_loss: 0.0026 - val_iou_score: 0.8519\n",
      "Epoch 84/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0028 - iou_score: 0.9265 - val_loss: 0.0033 - val_iou_score: 0.8408\n",
      "Epoch 85/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0027 - iou_score: 0.9257 - val_loss: 0.0028 - val_iou_score: 0.8494\n",
      "Epoch 86/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0025 - iou_score: 0.9315 - val_loss: 0.0026 - val_iou_score: 0.8512\n",
      "Epoch 87/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0023 - iou_score: 0.9373 - val_loss: 0.0027 - val_iou_score: 0.8512\n",
      "Epoch 88/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0022 - iou_score: 0.9405 - val_loss: 0.0027 - val_iou_score: 0.8536\n",
      "Epoch 89/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0021 - iou_score: 0.9399 - val_loss: 0.0028 - val_iou_score: 0.8569\n",
      "Epoch 90/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0026 - iou_score: 0.9308 - val_loss: 0.0028 - val_iou_score: 0.8552\n",
      "Epoch 91/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0026 - iou_score: 0.9311 - val_loss: 0.0024 - val_iou_score: 0.8577\n",
      "Epoch 92/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0021 - iou_score: 0.9406 - val_loss: 0.0025 - val_iou_score: 0.8587\n",
      "Epoch 93/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0067 - iou_score: 0.8520 - val_loss: 0.0550 - val_iou_score: 0.4286\n",
      "Epoch 94/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0112 - iou_score: 0.7400 - val_loss: 0.0150 - val_iou_score: 0.6644\n",
      "Epoch 95/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0041 - iou_score: 0.8801 - val_loss: 0.0034 - val_iou_score: 0.8288\n",
      "Epoch 96/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0027 - iou_score: 0.9225 - val_loss: 0.0026 - val_iou_score: 0.8465\n",
      "Epoch 97/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0025 - iou_score: 0.9327 - val_loss: 0.0065 - val_iou_score: 0.7920\n",
      "Epoch 98/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0028 - iou_score: 0.9225 - val_loss: 0.0026 - val_iou_score: 0.8496\n",
      "Epoch 99/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0028 - iou_score: 0.9261 - val_loss: 0.0031 - val_iou_score: 0.8441\n",
      "Epoch 100/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0022 - iou_score: 0.9405 - val_loss: 0.0026 - val_iou_score: 0.8557\n",
      "Epoch 101/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0020 - iou_score: 0.9438 - val_loss: 0.0025 - val_iou_score: 0.8592\n",
      "Epoch 102/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0021 - iou_score: 0.9429 - val_loss: 0.0023 - val_iou_score: 0.8655\n",
      "Epoch 103/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0020 - iou_score: 0.9471 - val_loss: 0.0023 - val_iou_score: 0.8649\n",
      "Epoch 104/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0021 - iou_score: 0.9429 - val_loss: 0.0020 - val_iou_score: 0.8681\n",
      "Epoch 105/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0018 - iou_score: 0.9489 - val_loss: 0.0021 - val_iou_score: 0.8685\n",
      "Epoch 106/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0018 - iou_score: 0.9500 - val_loss: 0.0020 - val_iou_score: 0.8710\n",
      "Epoch 107/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0019 - iou_score: 0.9484 - val_loss: 0.0019 - val_iou_score: 0.8734\n",
      "Epoch 108/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0018 - iou_score: 0.9521 - val_loss: 0.0023 - val_iou_score: 0.8679\n",
      "Epoch 109/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0018 - iou_score: 0.9490 - val_loss: 0.0019 - val_iou_score: 0.8734\n",
      "Epoch 110/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0019 - iou_score: 0.9498 - val_loss: 0.0021 - val_iou_score: 0.8696\n",
      "Epoch 111/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0019 - iou_score: 0.9477 - val_loss: 0.0022 - val_iou_score: 0.8684\n",
      "Epoch 112/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0017 - iou_score: 0.9534 - val_loss: 0.0025 - val_iou_score: 0.8656\n",
      "Epoch 113/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0016 - iou_score: 0.9440 - val_loss: 0.0020 - val_iou_score: 0.8731\n",
      "Epoch 114/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0017 - iou_score: 0.9541 - val_loss: 0.0018 - val_iou_score: 0.8766\n",
      "Epoch 115/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0016 - iou_score: 0.9548 - val_loss: 0.0020 - val_iou_score: 0.8744\n",
      "Epoch 116/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0019 - iou_score: 0.9502 - val_loss: 0.0020 - val_iou_score: 0.8743\n",
      "Epoch 117/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0018 - iou_score: 0.9495 - val_loss: 0.0025 - val_iou_score: 0.8652\n",
      "Epoch 118/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0018 - iou_score: 0.9399 - val_loss: 0.0022 - val_iou_score: 0.8699\n",
      "Epoch 119/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0016 - iou_score: 0.9545 - val_loss: 0.0021 - val_iou_score: 0.8735\n",
      "Epoch 120/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0017 - iou_score: 0.9543 - val_loss: 0.0018 - val_iou_score: 0.8770\n",
      "Epoch 121/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0017 - iou_score: 0.9532 - val_loss: 0.0019 - val_iou_score: 0.8757\n",
      "Epoch 122/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0016 - iou_score: 0.9560 - val_loss: 0.0021 - val_iou_score: 0.8730\n",
      "Epoch 123/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0016 - iou_score: 0.9460 - val_loss: 0.0023 - val_iou_score: 0.8670\n",
      "Epoch 124/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0018 - iou_score: 0.9296 - val_loss: 0.0018 - val_iou_score: 0.8763\n",
      "Epoch 125/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0015 - iou_score: 0.9576 - val_loss: 0.0021 - val_iou_score: 0.8748\n",
      "Epoch 126/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0018 - iou_score: 0.9500 - val_loss: 0.0018 - val_iou_score: 0.8765\n",
      "Epoch 127/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0015 - iou_score: 0.9569 - val_loss: 0.0019 - val_iou_score: 0.8781\n",
      "Epoch 128/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0016 - iou_score: 0.9583 - val_loss: 0.0018 - val_iou_score: 0.8781\n",
      "Epoch 129/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0014 - iou_score: 0.9602 - val_loss: 0.0017 - val_iou_score: 0.8810\n",
      "Epoch 130/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0017 - iou_score: 0.9426 - val_loss: 0.0017 - val_iou_score: 0.8802\n",
      "Epoch 131/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0015 - iou_score: 0.9591 - val_loss: 0.0017 - val_iou_score: 0.8798\n",
      "Epoch 132/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0015 - iou_score: 0.9596 - val_loss: 0.0019 - val_iou_score: 0.8793\n",
      "Epoch 133/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0014 - iou_score: 0.9607 - val_loss: 0.0017 - val_iou_score: 0.8829\n",
      "Epoch 134/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0163 - iou_score: 0.6634 - val_loss: 0.0477 - val_iou_score: 0.3838\n",
      "Epoch 135/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0077 - iou_score: 0.8058 - val_loss: 0.0044 - val_iou_score: 0.7942\n",
      "Epoch 136/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0034 - iou_score: 0.9074 - val_loss: 0.0030 - val_iou_score: 0.8352\n",
      "Epoch 137/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0022 - iou_score: 0.9371 - val_loss: 0.0023 - val_iou_score: 0.8564\n",
      "Epoch 138/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0019 - iou_score: 0.9462 - val_loss: 0.0022 - val_iou_score: 0.8648\n",
      "Epoch 139/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0017 - iou_score: 0.9530 - val_loss: 0.0021 - val_iou_score: 0.8689\n",
      "Epoch 140/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 0.0017 - iou_score: 0.9526 - val_loss: 0.0025 - val_iou_score: 0.8634\n",
      "Epoch 141/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0016 - iou_score: 0.9552 - val_loss: 0.0020 - val_iou_score: 0.8725\n",
      "Epoch 142/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0015 - iou_score: 0.9567 - val_loss: 0.0020 - val_iou_score: 0.8747\n",
      "Epoch 143/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0016 - iou_score: 0.9569 - val_loss: 0.0021 - val_iou_score: 0.8734\n",
      "Epoch 144/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0014 - iou_score: 0.9597 - val_loss: 0.0017 - val_iou_score: 0.8801\n",
      "Epoch 145/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0013 - iou_score: 0.9521 - val_loss: 0.0017 - val_iou_score: 0.8820\n",
      "Epoch 146/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9633 - val_loss: 0.0017 - val_iou_score: 0.8827\n",
      "Epoch 147/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0014 - iou_score: 0.9620 - val_loss: 0.0018 - val_iou_score: 0.8809\n",
      "Epoch 148/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0014 - iou_score: 0.9511 - val_loss: 0.0019 - val_iou_score: 0.8809\n",
      "Epoch 149/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0012 - iou_score: 0.9544 - val_loss: 0.0016 - val_iou_score: 0.8851\n",
      "Epoch 150/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0014 - iou_score: 0.9632 - val_loss: 0.0026 - val_iou_score: 0.8697\n",
      "Epoch 151/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 0.0015 - iou_score: 0.9595 - val_loss: 0.0015 - val_iou_score: 0.8859\n",
      "Epoch 152/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0012 - iou_score: 0.9659 - val_loss: 0.0015 - val_iou_score: 0.8860\n",
      "Epoch 153/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0012 - iou_score: 0.9552 - val_loss: 0.0016 - val_iou_score: 0.8850\n",
      "Epoch 154/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9630 - val_loss: 0.0018 - val_iou_score: 0.8818\n",
      "Epoch 155/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 0.0014 - iou_score: 0.9614 - val_loss: 0.0020 - val_iou_score: 0.8807\n",
      "Epoch 156/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0014 - iou_score: 0.9405 - val_loss: 0.0016 - val_iou_score: 0.8861\n",
      "Epoch 157/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0011 - iou_score: 0.9681 - val_loss: 0.0015 - val_iou_score: 0.8882\n",
      "Epoch 158/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0012 - iou_score: 0.9653 - val_loss: 0.0016 - val_iou_score: 0.8862\n",
      "Epoch 159/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9647 - val_loss: 0.0022 - val_iou_score: 0.8784\n",
      "Epoch 160/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0013 - iou_score: 0.9631 - val_loss: 0.0016 - val_iou_score: 0.8861\n",
      "Epoch 161/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0012 - iou_score: 0.9667 - val_loss: 0.0017 - val_iou_score: 0.8853\n",
      "Epoch 162/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9640 - val_loss: 0.0016 - val_iou_score: 0.8857\n",
      "Epoch 163/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0012 - iou_score: 0.9663 - val_loss: 0.0019 - val_iou_score: 0.8811\n",
      "Epoch 164/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0012 - iou_score: 0.9659 - val_loss: 0.0016 - val_iou_score: 0.8880\n",
      "Epoch 165/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9538 - val_loss: 0.0019 - val_iou_score: 0.8820\n",
      "Epoch 166/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0012 - iou_score: 0.9648 - val_loss: 0.0016 - val_iou_score: 0.8866\n",
      "Epoch 167/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0036 - iou_score: 0.9164 - val_loss: 0.0038 - val_iou_score: 0.8426\n",
      "Epoch 168/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0016 - iou_score: 0.9435 - val_loss: 0.0022 - val_iou_score: 0.8759\n",
      "Epoch 169/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9642 - val_loss: 0.0017 - val_iou_score: 0.8837\n",
      "Epoch 170/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0012 - iou_score: 0.9664 - val_loss: 0.0015 - val_iou_score: 0.8877\n",
      "Epoch 171/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0014 - iou_score: 0.9652 - val_loss: 0.0040 - val_iou_score: 0.8442\n",
      "Epoch 172/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0030 - iou_score: 0.9177 - val_loss: 0.0022 - val_iou_score: 0.8671\n",
      "Epoch 173/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0014 - iou_score: 0.9591 - val_loss: 0.0015 - val_iou_score: 0.8836\n",
      "Epoch 174/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0013 - iou_score: 0.9647 - val_loss: 0.0015 - val_iou_score: 0.8862\n",
      "Epoch 175/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0012 - iou_score: 0.9654 - val_loss: 0.0015 - val_iou_score: 0.8865\n",
      "Epoch 176/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0011 - iou_score: 0.9691 - val_loss: 0.0015 - val_iou_score: 0.8881\n",
      "Epoch 177/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0011 - iou_score: 0.9684 - val_loss: 0.0015 - val_iou_score: 0.8895\n",
      "Epoch 178/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0013 - iou_score: 0.9658 - val_loss: 0.0015 - val_iou_score: 0.8893\n",
      "Epoch 179/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0012 - iou_score: 0.9682 - val_loss: 0.0016 - val_iou_score: 0.8893\n",
      "Epoch 180/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0011 - iou_score: 0.9691 - val_loss: 0.0015 - val_iou_score: 0.8904\n",
      "Epoch 181/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0011 - iou_score: 0.9695 - val_loss: 0.0014 - val_iou_score: 0.8911\n",
      "Epoch 182/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0011 - iou_score: 0.9711 - val_loss: 0.0016 - val_iou_score: 0.8886\n",
      "Epoch 183/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0011 - iou_score: 0.9701 - val_loss: 0.0013 - val_iou_score: 0.8929\n",
      "Epoch 184/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0010 - iou_score: 0.9720 - val_loss: 0.0016 - val_iou_score: 0.8904\n",
      "Epoch 185/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0010 - iou_score: 0.9709 - val_loss: 0.0013 - val_iou_score: 0.8930\n",
      "Epoch 186/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0010 - iou_score: 0.9716 - val_loss: 0.0016 - val_iou_score: 0.8889\n",
      "Epoch 187/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0011 - iou_score: 0.9711 - val_loss: 0.0014 - val_iou_score: 0.8933\n",
      "Epoch 188/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.4727e-04 - iou_score: 0.9735 - val_loss: 0.0016 - val_iou_score: 0.8902\n",
      "Epoch 189/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0012 - iou_score: 0.9688 - val_loss: 0.0017 - val_iou_score: 0.8861\n",
      "Epoch 190/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0014 - iou_score: 0.9605 - val_loss: 0.0020 - val_iou_score: 0.8779\n",
      "Epoch 191/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9610 - val_loss: 0.0014 - val_iou_score: 0.8889\n",
      "Epoch 192/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 9.9629e-04 - iou_score: 0.9714 - val_loss: 0.0014 - val_iou_score: 0.8917\n",
      "Epoch 193/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.8185e-04 - iou_score: 0.9749 - val_loss: 0.0016 - val_iou_score: 0.8900\n",
      "Epoch 194/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0010 - iou_score: 0.9601 - val_loss: 0.0017 - val_iou_score: 0.8885\n",
      "Epoch 195/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 0.0010 - iou_score: 0.9728 - val_loss: 0.0016 - val_iou_score: 0.8908\n",
      "Epoch 196/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0011 - iou_score: 0.9708 - val_loss: 0.0015 - val_iou_score: 0.8893\n",
      "Epoch 197/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 9.9461e-04 - iou_score: 0.9721 - val_loss: 0.0015 - val_iou_score: 0.8921\n",
      "Epoch 198/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.2296e-04 - iou_score: 0.9741 - val_loss: 0.0015 - val_iou_score: 0.8928\n",
      "Epoch 199/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9671 - val_loss: 0.0017 - val_iou_score: 0.8883\n",
      "Epoch 200/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0010 - iou_score: 0.9719 - val_loss: 0.0014 - val_iou_score: 0.8927\n",
      "Epoch 201/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.3399e-04 - iou_score: 0.9741 - val_loss: 0.0014 - val_iou_score: 0.8940\n",
      "Epoch 202/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 8.5140e-04 - iou_score: 0.9759 - val_loss: 0.0013 - val_iou_score: 0.8958\n",
      "Epoch 203/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0010 - iou_score: 0.9619 - val_loss: 0.0018 - val_iou_score: 0.8893\n",
      "Epoch 204/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.6058e-04 - iou_score: 0.9729 - val_loss: 0.0012 - val_iou_score: 0.8965\n",
      "Epoch 205/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.7073e-04 - iou_score: 0.9632 - val_loss: 0.0015 - val_iou_score: 0.8930\n",
      "Epoch 206/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0012 - iou_score: 0.9678 - val_loss: 0.0014 - val_iou_score: 0.8933\n",
      "Epoch 207/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 9.7188e-04 - iou_score: 0.9732 - val_loss: 0.0013 - val_iou_score: 0.8954\n",
      "Epoch 208/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 7.8391e-04 - iou_score: 0.9773 - val_loss: 0.0012 - val_iou_score: 0.8982\n",
      "Epoch 209/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.4910e-04 - iou_score: 0.9770 - val_loss: 0.0015 - val_iou_score: 0.8946\n",
      "Epoch 210/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0010 - iou_score: 0.9611 - val_loss: 0.0016 - val_iou_score: 0.8889\n",
      "Epoch 211/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.5540e-04 - iou_score: 0.9727 - val_loss: 0.0014 - val_iou_score: 0.8959\n",
      "Epoch 212/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0010 - iou_score: 0.9726 - val_loss: 0.0015 - val_iou_score: 0.8922\n",
      "Epoch 213/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.4176e-04 - iou_score: 0.9737 - val_loss: 0.0013 - val_iou_score: 0.8961\n",
      "Epoch 214/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.8317e-04 - iou_score: 0.9733 - val_loss: 0.0016 - val_iou_score: 0.8917\n",
      "Epoch 215/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.1220e-04 - iou_score: 0.9762 - val_loss: 0.0013 - val_iou_score: 0.8972\n",
      "Epoch 216/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.4689e-04 - iou_score: 0.9746 - val_loss: 0.0016 - val_iou_score: 0.8923\n",
      "Epoch 217/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 9.1532e-04 - iou_score: 0.9739 - val_loss: 0.0014 - val_iou_score: 0.8957\n",
      "Epoch 218/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.0111e-04 - iou_score: 0.9753 - val_loss: 0.0014 - val_iou_score: 0.8949\n",
      "Epoch 219/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.5778e-04 - iou_score: 0.9731 - val_loss: 0.0014 - val_iou_score: 0.8942\n",
      "Epoch 220/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.3762e-04 - iou_score: 0.9648 - val_loss: 0.0016 - val_iou_score: 0.8928\n",
      "Epoch 221/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.5667e-04 - iou_score: 0.9742 - val_loss: 0.0014 - val_iou_score: 0.8957\n",
      "Epoch 222/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 7.9529e-04 - iou_score: 0.9774 - val_loss: 0.0013 - val_iou_score: 0.8986\n",
      "Epoch 223/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.9601e-04 - iou_score: 0.9750 - val_loss: 0.0015 - val_iou_score: 0.8942\n",
      "Epoch 224/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.0440e-04 - iou_score: 0.9764 - val_loss: 0.0014 - val_iou_score: 0.8971\n",
      "Epoch 225/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 9.3543e-04 - iou_score: 0.9751 - val_loss: 0.0013 - val_iou_score: 0.8981\n",
      "Epoch 226/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.4732e-04 - iou_score: 0.9749 - val_loss: 0.0019 - val_iou_score: 0.8872\n",
      "Epoch 227/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.6732e-04 - iou_score: 0.9748 - val_loss: 0.0012 - val_iou_score: 0.8984\n",
      "Epoch 228/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.7952e-04 - iou_score: 0.9779 - val_loss: 0.0014 - val_iou_score: 0.8956\n",
      "Epoch 229/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.9675e-04 - iou_score: 0.9776 - val_loss: 0.0013 - val_iou_score: 0.8973\n",
      "Epoch 230/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.3780e-04 - iou_score: 0.9683 - val_loss: 0.0014 - val_iou_score: 0.8978\n",
      "Epoch 231/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.9216e-04 - iou_score: 0.9758 - val_loss: 0.0018 - val_iou_score: 0.8912\n",
      "Epoch 232/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.1160e-04 - iou_score: 0.9744 - val_loss: 0.0014 - val_iou_score: 0.8965\n",
      "Epoch 233/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.2751e-04 - iou_score: 0.9752 - val_loss: 0.0015 - val_iou_score: 0.8945\n",
      "Epoch 234/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.0203e-04 - iou_score: 0.9749 - val_loss: 0.0013 - val_iou_score: 0.8976\n",
      "Epoch 235/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.8039e-04 - iou_score: 0.9807 - val_loss: 0.0013 - val_iou_score: 0.8999\n",
      "Epoch 236/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.9417e-04 - iou_score: 0.9807 - val_loss: 0.0012 - val_iou_score: 0.9003\n",
      "Epoch 237/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.7268e-04 - iou_score: 0.9791 - val_loss: 0.0014 - val_iou_score: 0.8985\n",
      "Epoch 238/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.3977e-04 - iou_score: 0.9771 - val_loss: 0.0013 - val_iou_score: 0.8974\n",
      "Epoch 239/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.6338e-04 - iou_score: 0.9788 - val_loss: 0.0014 - val_iou_score: 0.8966\n",
      "Epoch 240/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.1850e-04 - iou_score: 0.9775 - val_loss: 0.0013 - val_iou_score: 0.8977\n",
      "Epoch 241/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.8165e-04 - iou_score: 0.9785 - val_loss: 0.0014 - val_iou_score: 0.8969\n",
      "Epoch 242/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.5906e-04 - iou_score: 0.9804 - val_loss: 0.0012 - val_iou_score: 0.9015\n",
      "Epoch 243/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.5528e-04 - iou_score: 0.9777 - val_loss: 0.0017 - val_iou_score: 0.8945\n",
      "Epoch 244/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.0831e-04 - iou_score: 0.9795 - val_loss: 0.0013 - val_iou_score: 0.9010\n",
      "Epoch 245/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.7862e-04 - iou_score: 0.9811 - val_loss: 0.0014 - val_iou_score: 0.8975\n",
      "Epoch 246/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 7.1997e-04 - iou_score: 0.9803 - val_loss: 0.0014 - val_iou_score: 0.8995\n",
      "Epoch 247/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 8.4044e-04 - iou_score: 0.9781 - val_loss: 0.0018 - val_iou_score: 0.8899\n",
      "Epoch 248/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.2380e-04 - iou_score: 0.9763 - val_loss: 0.0013 - val_iou_score: 0.8991\n",
      "Epoch 249/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.3094e-04 - iou_score: 0.9820 - val_loss: 0.0012 - val_iou_score: 0.9007\n",
      "Epoch 250/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.0663e-04 - iou_score: 0.9697 - val_loss: 0.0018 - val_iou_score: 0.8942\n",
      "Epoch 251/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.7343e-04 - iou_score: 0.9759 - val_loss: 0.0014 - val_iou_score: 0.8981\n",
      "Epoch 252/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.0418e-04 - iou_score: 0.9804 - val_loss: 0.0015 - val_iou_score: 0.8982\n",
      "Epoch 253/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.3175e-04 - iou_score: 0.9822 - val_loss: 0.0015 - val_iou_score: 0.8997\n",
      "Epoch 254/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.2295e-04 - iou_score: 0.9696 - val_loss: 0.0014 - val_iou_score: 0.9000\n",
      "Epoch 255/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.4389e-04 - iou_score: 0.9690 - val_loss: 0.0025 - val_iou_score: 0.8896\n",
      "Epoch 256/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0011 - iou_score: 0.9708 - val_loss: 0.0015 - val_iou_score: 0.8963\n",
      "Epoch 257/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.5355e-04 - iou_score: 0.9812 - val_loss: 0.0013 - val_iou_score: 0.8991\n",
      "Epoch 258/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.5298e-04 - iou_score: 0.9768 - val_loss: 0.0015 - val_iou_score: 0.8944\n",
      "Epoch 259/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.7464e-04 - iou_score: 0.9805 - val_loss: 0.0016 - val_iou_score: 0.8973\n",
      "Epoch 260/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.8484e-04 - iou_score: 0.9764 - val_loss: 0.0017 - val_iou_score: 0.8930\n",
      "Epoch 261/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.5915e-04 - iou_score: 0.9805 - val_loss: 0.0014 - val_iou_score: 0.8992\n",
      "Epoch 262/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.7858e-04 - iou_score: 0.9612 - val_loss: 0.0014 - val_iou_score: 0.9000\n",
      "Epoch 263/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.0889e-04 - iou_score: 0.9856 - val_loss: 0.0014 - val_iou_score: 0.9019\n",
      "Epoch 264/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.6068e-04 - iou_score: 0.9821 - val_loss: 0.0015 - val_iou_score: 0.8968\n",
      "Epoch 265/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.6847e-04 - iou_score: 0.9808 - val_loss: 0.0014 - val_iou_score: 0.8989\n",
      "Epoch 266/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.5553e-04 - iou_score: 0.9817 - val_loss: 0.0016 - val_iou_score: 0.8965\n",
      "Epoch 267/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.6151e-04 - iou_score: 0.9763 - val_loss: 0.0013 - val_iou_score: 0.8994\n",
      "Epoch 268/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.2092e-04 - iou_score: 0.9828 - val_loss: 0.0018 - val_iou_score: 0.8985\n",
      "Epoch 269/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.2643e-04 - iou_score: 0.9779 - val_loss: 0.0015 - val_iou_score: 0.8976\n",
      "Epoch 270/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.2344e-04 - iou_score: 0.9687 - val_loss: 0.0013 - val_iou_score: 0.9014\n",
      "Epoch 271/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.2196e-04 - iou_score: 0.9846 - val_loss: 0.0013 - val_iou_score: 0.9021\n",
      "Epoch 272/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.8855e-04 - iou_score: 0.9751 - val_loss: 0.0013 - val_iou_score: 0.9032\n",
      "Epoch 273/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.1144e-04 - iou_score: 0.9839 - val_loss: 0.0015 - val_iou_score: 0.9000\n",
      "Epoch 274/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.7960e-04 - iou_score: 0.9839 - val_loss: 0.0017 - val_iou_score: 0.8980\n",
      "Epoch 275/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.7520e-04 - iou_score: 0.9841 - val_loss: 0.0014 - val_iou_score: 0.9007\n",
      "Epoch 276/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.7325e-04 - iou_score: 0.9807 - val_loss: 0.0016 - val_iou_score: 0.8972\n",
      "Epoch 277/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.6747e-04 - iou_score: 0.9726 - val_loss: 0.0013 - val_iou_score: 0.9034\n",
      "Epoch 278/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.8203e-04 - iou_score: 0.9859 - val_loss: 0.0014 - val_iou_score: 0.9025\n",
      "Epoch 279/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.0995e-04 - iou_score: 0.9855 - val_loss: 0.0017 - val_iou_score: 0.9010\n",
      "Epoch 280/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.8434e-04 - iou_score: 0.9808 - val_loss: 0.0016 - val_iou_score: 0.8996\n",
      "Epoch 281/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.8014e-04 - iou_score: 0.9753 - val_loss: 0.0015 - val_iou_score: 0.8970\n",
      "Epoch 282/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.5858e-04 - iou_score: 0.9813 - val_loss: 0.0014 - val_iou_score: 0.8996\n",
      "Epoch 283/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.4278e-04 - iou_score: 0.9811 - val_loss: 0.0013 - val_iou_score: 0.9009\n",
      "Epoch 284/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.0490e-04 - iou_score: 0.9850 - val_loss: 0.0013 - val_iou_score: 0.9033\n",
      "Epoch 285/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.1977e-04 - iou_score: 0.9742 - val_loss: 0.0015 - val_iou_score: 0.9017\n",
      "Epoch 286/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.4281e-04 - iou_score: 0.9798 - val_loss: 0.0014 - val_iou_score: 0.9018\n",
      "Epoch 287/1400\n",
      "89/89 [==============================] - 22s 253ms/step - loss: 4.9870e-04 - iou_score: 0.9854 - val_loss: 0.0012 - val_iou_score: 0.9042\n",
      "Epoch 288/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.0261e-04 - iou_score: 0.9856 - val_loss: 0.0014 - val_iou_score: 0.9031\n",
      "Epoch 289/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.1088e-04 - iou_score: 0.9746 - val_loss: 0.0012 - val_iou_score: 0.9058\n",
      "Epoch 290/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.0780e-04 - iou_score: 0.9840 - val_loss: 0.0013 - val_iou_score: 0.9035\n",
      "Epoch 291/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 4.4978e-04 - iou_score: 0.9869 - val_loss: 0.0013 - val_iou_score: 0.9046\n",
      "Epoch 292/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.7450e-04 - iou_score: 0.9871 - val_loss: 0.0014 - val_iou_score: 0.9030\n",
      "Epoch 293/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.6484e-04 - iou_score: 0.9824 - val_loss: 0.0015 - val_iou_score: 0.8991\n",
      "Epoch 294/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.2685e-04 - iou_score: 0.9845 - val_loss: 0.0013 - val_iou_score: 0.9031\n",
      "Epoch 295/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.6512e-04 - iou_score: 0.9849 - val_loss: 0.0013 - val_iou_score: 0.9047\n",
      "Epoch 296/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.1840e-04 - iou_score: 0.9740 - val_loss: 0.0015 - val_iou_score: 0.9029\n",
      "Epoch 297/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.1679e-04 - iou_score: 0.9875 - val_loss: 0.0012 - val_iou_score: 0.9071\n",
      "Epoch 298/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.0744e-04 - iou_score: 0.9884 - val_loss: 0.0014 - val_iou_score: 0.9048\n",
      "Epoch 299/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.7199e-04 - iou_score: 0.9875 - val_loss: 0.0015 - val_iou_score: 0.9036\n",
      "Epoch 300/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.5094e-04 - iou_score: 0.9875 - val_loss: 0.0014 - val_iou_score: 0.9047\n",
      "Epoch 301/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.9839e-04 - iou_score: 0.9869 - val_loss: 0.0014 - val_iou_score: 0.9030\n",
      "Epoch 302/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.6155e-04 - iou_score: 0.9845 - val_loss: 0.0015 - val_iou_score: 0.9021\n",
      "Epoch 303/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.7305e-04 - iou_score: 0.9866 - val_loss: 0.0013 - val_iou_score: 0.9051\n",
      "Epoch 304/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.9549e-04 - iou_score: 0.9862 - val_loss: 0.0019 - val_iou_score: 0.9016\n",
      "Epoch 305/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.1741e-04 - iou_score: 0.9862 - val_loss: 0.0013 - val_iou_score: 0.9050\n",
      "Epoch 306/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.0938e-04 - iou_score: 0.9882 - val_loss: 0.0015 - val_iou_score: 0.9044\n",
      "Epoch 307/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 7.2023e-04 - iou_score: 0.9714 - val_loss: 0.0013 - val_iou_score: 0.9034\n",
      "Epoch 308/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.6007e-04 - iou_score: 0.9867 - val_loss: 0.0012 - val_iou_score: 0.9046\n",
      "Epoch 309/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.1390e-04 - iou_score: 0.9883 - val_loss: 0.0013 - val_iou_score: 0.9036\n",
      "Epoch 310/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.1556e-04 - iou_score: 0.9876 - val_loss: 0.0016 - val_iou_score: 0.9011\n",
      "Epoch 311/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.0865e-04 - iou_score: 0.9840 - val_loss: 0.0016 - val_iou_score: 0.8983\n",
      "Epoch 312/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 6.8447e-04 - iou_score: 0.9816 - val_loss: 0.0015 - val_iou_score: 0.9001\n",
      "Epoch 313/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.4612e-04 - iou_score: 0.9794 - val_loss: 0.0012 - val_iou_score: 0.9030\n",
      "Epoch 314/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.1078e-04 - iou_score: 0.9874 - val_loss: 0.0011 - val_iou_score: 0.9064\n",
      "Epoch 315/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.5233e-04 - iou_score: 0.9895 - val_loss: 0.0013 - val_iou_score: 0.9052\n",
      "Epoch 316/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0041 - iou_score: 0.9498 - val_loss: 0.0694 - val_iou_score: 0.5960\n",
      "Epoch 317/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0070 - iou_score: 0.8467 - val_loss: 0.0084 - val_iou_score: 0.7894\n",
      "Epoch 318/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0018 - iou_score: 0.9486 - val_loss: 0.0038 - val_iou_score: 0.8711\n",
      "Epoch 319/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9641 - val_loss: 0.0016 - val_iou_score: 0.8851\n",
      "Epoch 320/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 9.5145e-04 - iou_score: 0.9729 - val_loss: 0.0014 - val_iou_score: 0.8915\n",
      "Epoch 321/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.5626e-04 - iou_score: 0.9780 - val_loss: 0.0013 - val_iou_score: 0.8959\n",
      "Epoch 322/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.5160e-04 - iou_score: 0.9811 - val_loss: 0.0014 - val_iou_score: 0.8964\n",
      "Epoch 323/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.4625e-04 - iou_score: 0.9822 - val_loss: 0.0012 - val_iou_score: 0.9006\n",
      "Epoch 324/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.7268e-04 - iou_score: 0.9839 - val_loss: 0.0012 - val_iou_score: 0.9019\n",
      "Epoch 325/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 5.1350e-04 - iou_score: 0.9850 - val_loss: 0.0012 - val_iou_score: 0.9024\n",
      "Epoch 326/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.8087e-04 - iou_score: 0.9861 - val_loss: 0.0012 - val_iou_score: 0.9041\n",
      "Epoch 327/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.2279e-04 - iou_score: 0.9876 - val_loss: 0.0012 - val_iou_score: 0.9037\n",
      "Epoch 328/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.6607e-04 - iou_score: 0.9761 - val_loss: 0.0013 - val_iou_score: 0.9041\n",
      "Epoch 329/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 5.0031e-04 - iou_score: 0.9865 - val_loss: 0.0013 - val_iou_score: 0.9033\n",
      "Epoch 330/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.3630e-04 - iou_score: 0.9876 - val_loss: 0.0012 - val_iou_score: 0.9058\n",
      "Epoch 331/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.9119e-04 - iou_score: 0.9889 - val_loss: 0.0012 - val_iou_score: 0.9057\n",
      "Epoch 332/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.0568e-04 - iou_score: 0.9887 - val_loss: 0.0012 - val_iou_score: 0.9062\n",
      "Epoch 333/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.7968e-04 - iou_score: 0.9893 - val_loss: 0.0013 - val_iou_score: 0.9059\n",
      "Epoch 334/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.8628e-04 - iou_score: 0.9893 - val_loss: 0.0012 - val_iou_score: 0.9069\n",
      "Epoch 335/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 5.0431e-04 - iou_score: 0.9871 - val_loss: 0.0014 - val_iou_score: 0.9039\n",
      "Epoch 336/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 5.2545e-04 - iou_score: 0.9749 - val_loss: 0.0012 - val_iou_score: 0.9050\n",
      "Epoch 337/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.1751e-04 - iou_score: 0.9880 - val_loss: 0.0013 - val_iou_score: 0.9057\n",
      "Epoch 338/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.5995e-04 - iou_score: 0.9891 - val_loss: 0.0012 - val_iou_score: 0.9076\n",
      "Epoch 339/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.1680e-04 - iou_score: 0.9907 - val_loss: 0.0012 - val_iou_score: 0.9085\n",
      "Epoch 340/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.1924e-04 - iou_score: 0.9907 - val_loss: 0.0013 - val_iou_score: 0.9067\n",
      "Epoch 341/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.3075e-04 - iou_score: 0.9886 - val_loss: 0.0015 - val_iou_score: 0.9051\n",
      "Epoch 342/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 5.7429e-04 - iou_score: 0.9861 - val_loss: 0.0012 - val_iou_score: 0.9054\n",
      "Epoch 343/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.8889e-04 - iou_score: 0.9773 - val_loss: 0.0012 - val_iou_score: 0.9069\n",
      "Epoch 344/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.3476e-04 - iou_score: 0.9904 - val_loss: 0.0012 - val_iou_score: 0.9077\n",
      "Epoch 345/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.7147e-04 - iou_score: 0.9899 - val_loss: 0.0012 - val_iou_score: 0.9085\n",
      "Epoch 346/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.6060e-04 - iou_score: 0.9900 - val_loss: 0.0013 - val_iou_score: 0.9060\n",
      "Epoch 347/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.9266e-04 - iou_score: 0.9894 - val_loss: 0.0013 - val_iou_score: 0.9070\n",
      "Epoch 348/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.5743e-04 - iou_score: 0.9900 - val_loss: 0.0012 - val_iou_score: 0.9078\n",
      "Epoch 349/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.4542e-04 - iou_score: 0.9903 - val_loss: 0.0012 - val_iou_score: 0.9083\n",
      "Epoch 350/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.4987e-04 - iou_score: 0.9900 - val_loss: 0.0012 - val_iou_score: 0.9082\n",
      "Epoch 351/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.2914e-04 - iou_score: 0.9907 - val_loss: 0.0012 - val_iou_score: 0.9088\n",
      "Epoch 352/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.8815e-04 - iou_score: 0.9789 - val_loss: 0.0013 - val_iou_score: 0.9077\n",
      "Epoch 353/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.8553e-04 - iou_score: 0.9877 - val_loss: 0.0014 - val_iou_score: 0.9047\n",
      "Epoch 354/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.7975e-04 - iou_score: 0.9804 - val_loss: 0.0012 - val_iou_score: 0.9057\n",
      "Epoch 355/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.9858e-04 - iou_score: 0.9852 - val_loss: 0.0012 - val_iou_score: 0.9049\n",
      "Epoch 356/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.1673e-04 - iou_score: 0.9901 - val_loss: 0.0012 - val_iou_score: 0.9079\n",
      "Epoch 357/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 2.5700e-04 - iou_score: 0.9918 - val_loss: 0.0012 - val_iou_score: 0.9087\n",
      "Epoch 358/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.9983e-04 - iou_score: 0.9916 - val_loss: 0.0014 - val_iou_score: 0.9075\n",
      "Epoch 359/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.0233e-04 - iou_score: 0.9879 - val_loss: 0.0018 - val_iou_score: 0.9006\n",
      "Epoch 360/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.5370e-04 - iou_score: 0.9851 - val_loss: 0.0014 - val_iou_score: 0.9046\n",
      "Epoch 361/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 5.5656e-04 - iou_score: 0.9870 - val_loss: 0.0017 - val_iou_score: 0.9000\n",
      "Epoch 362/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.2619e-04 - iou_score: 0.9809 - val_loss: 0.0012 - val_iou_score: 0.9041\n",
      "Epoch 363/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.3469e-04 - iou_score: 0.9899 - val_loss: 0.0011 - val_iou_score: 0.9082\n",
      "Epoch 364/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.9398e-04 - iou_score: 0.9913 - val_loss: 0.0012 - val_iou_score: 0.9083\n",
      "Epoch 365/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.3423e-04 - iou_score: 0.9793 - val_loss: 0.0012 - val_iou_score: 0.9084\n",
      "Epoch 366/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.3667e-04 - iou_score: 0.9885 - val_loss: 0.0012 - val_iou_score: 0.9070\n",
      "Epoch 367/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.0816e-04 - iou_score: 0.9892 - val_loss: 0.0012 - val_iou_score: 0.9073\n",
      "Epoch 368/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.4589e-04 - iou_score: 0.9901 - val_loss: 0.0013 - val_iou_score: 0.9075\n",
      "Epoch 369/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.1071e-04 - iou_score: 0.9857 - val_loss: 0.0014 - val_iou_score: 0.9005\n",
      "Epoch 370/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.2672e-04 - iou_score: 0.9852 - val_loss: 0.0012 - val_iou_score: 0.9070\n",
      "Epoch 371/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5744e-04 - iou_score: 0.9805 - val_loss: 0.0012 - val_iou_score: 0.9088\n",
      "Epoch 372/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.6701e-04 - iou_score: 0.9922 - val_loss: 0.0014 - val_iou_score: 0.9059\n",
      "Epoch 373/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0026 - iou_score: 0.9488 - val_loss: 0.0050 - val_iou_score: 0.8284\n",
      "Epoch 374/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0017 - iou_score: 0.9498 - val_loss: 0.0015 - val_iou_score: 0.8892\n",
      "Epoch 375/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.7411e-04 - iou_score: 0.9791 - val_loss: 0.0013 - val_iou_score: 0.8984\n",
      "Epoch 376/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 5.8598e-04 - iou_score: 0.9823 - val_loss: 0.0012 - val_iou_score: 0.9011\n",
      "Epoch 377/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.8230e-04 - iou_score: 0.9879 - val_loss: 0.0012 - val_iou_score: 0.9055\n",
      "Epoch 378/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.4210e-04 - iou_score: 0.9894 - val_loss: 0.0012 - val_iou_score: 0.9069\n",
      "Epoch 379/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.1946e-04 - iou_score: 0.9899 - val_loss: 0.0014 - val_iou_score: 0.9064\n",
      "Epoch 380/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.7790e-04 - iou_score: 0.9894 - val_loss: 0.0012 - val_iou_score: 0.9075\n",
      "Epoch 381/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 2.8469e-04 - iou_score: 0.9913 - val_loss: 0.0013 - val_iou_score: 0.9076\n",
      "Epoch 382/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.6727e-04 - iou_score: 0.9916 - val_loss: 0.0012 - val_iou_score: 0.9096\n",
      "Epoch 383/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8706e-04 - iou_score: 0.9918 - val_loss: 0.0013 - val_iou_score: 0.9089\n",
      "Epoch 384/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.8258e-04 - iou_score: 0.9902 - val_loss: 0.0016 - val_iou_score: 0.9037\n",
      "Epoch 385/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.4625e-04 - iou_score: 0.9872 - val_loss: 0.0018 - val_iou_score: 0.9042\n",
      "Epoch 386/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.6088e-04 - iou_score: 0.9876 - val_loss: 0.0013 - val_iou_score: 0.9065\n",
      "Epoch 387/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.7735e-04 - iou_score: 0.9917 - val_loss: 0.0011 - val_iou_score: 0.9105\n",
      "Epoch 388/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5539e-04 - iou_score: 0.9925 - val_loss: 0.0012 - val_iou_score: 0.9091\n",
      "Epoch 389/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.2578e-04 - iou_score: 0.9911 - val_loss: 0.0013 - val_iou_score: 0.9082\n",
      "Epoch 390/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.2040e-04 - iou_score: 0.9894 - val_loss: 0.0014 - val_iou_score: 0.9053\n",
      "Epoch 391/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.4663e-04 - iou_score: 0.9881 - val_loss: 0.0013 - val_iou_score: 0.9086\n",
      "Epoch 392/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.5647e-04 - iou_score: 0.9922 - val_loss: 0.0011 - val_iou_score: 0.9112\n",
      "Epoch 393/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.2666e-04 - iou_score: 0.9909 - val_loss: 0.0013 - val_iou_score: 0.9077\n",
      "Epoch 394/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8500e-04 - iou_score: 0.9803 - val_loss: 0.0013 - val_iou_score: 0.9089\n",
      "Epoch 395/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8214e-04 - iou_score: 0.9921 - val_loss: 0.0013 - val_iou_score: 0.9101\n",
      "Epoch 396/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.6126e-04 - iou_score: 0.9926 - val_loss: 0.0013 - val_iou_score: 0.9094\n",
      "Epoch 397/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 3.4138e-04 - iou_score: 0.9914 - val_loss: 0.0014 - val_iou_score: 0.9092\n",
      "Epoch 398/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.3584e-04 - iou_score: 0.9930 - val_loss: 0.0014 - val_iou_score: 0.9088\n",
      "Epoch 399/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.6062e-04 - iou_score: 0.9928 - val_loss: 0.0012 - val_iou_score: 0.9112\n",
      "Epoch 400/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8734e-04 - iou_score: 0.9923 - val_loss: 0.0013 - val_iou_score: 0.9095\n",
      "Epoch 401/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.4427e-04 - iou_score: 0.9801 - val_loss: 0.0014 - val_iou_score: 0.9073\n",
      "Epoch 402/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.8063e-04 - iou_score: 0.9905 - val_loss: 0.0013 - val_iou_score: 0.9093\n",
      "Epoch 403/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.9741e-04 - iou_score: 0.9916 - val_loss: 0.0014 - val_iou_score: 0.9051\n",
      "Epoch 404/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.0974e-04 - iou_score: 0.9799 - val_loss: 0.0013 - val_iou_score: 0.9082\n",
      "Epoch 405/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.3407e-04 - iou_score: 0.9931 - val_loss: 0.0012 - val_iou_score: 0.9114\n",
      "Epoch 406/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5168e-04 - iou_score: 0.9928 - val_loss: 0.0015 - val_iou_score: 0.9079\n",
      "Epoch 407/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.0248e-04 - iou_score: 0.9903 - val_loss: 0.0016 - val_iou_score: 0.9051\n",
      "Epoch 408/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.8343e-04 - iou_score: 0.9854 - val_loss: 0.0012 - val_iou_score: 0.9080\n",
      "Epoch 409/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.0772e-04 - iou_score: 0.9912 - val_loss: 0.0012 - val_iou_score: 0.9101\n",
      "Epoch 410/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.0359e-04 - iou_score: 0.9825 - val_loss: 0.0012 - val_iou_score: 0.9108\n",
      "Epoch 411/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.3336e-04 - iou_score: 0.9933 - val_loss: 0.0014 - val_iou_score: 0.9094\n",
      "Epoch 412/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.6460e-04 - iou_score: 0.9903 - val_loss: 0.0013 - val_iou_score: 0.9092\n",
      "Epoch 413/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.8910e-04 - iou_score: 0.9907 - val_loss: 0.0016 - val_iou_score: 0.9056\n",
      "Epoch 414/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.9549e-04 - iou_score: 0.9859 - val_loss: 0.0013 - val_iou_score: 0.9068\n",
      "Epoch 415/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.8051e-04 - iou_score: 0.9891 - val_loss: 0.0011 - val_iou_score: 0.9088\n",
      "Epoch 416/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9013e-04 - iou_score: 0.9939 - val_loss: 0.0011 - val_iou_score: 0.9114\n",
      "Epoch 417/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.7510e-04 - iou_score: 0.9948 - val_loss: 0.0013 - val_iou_score: 0.9101\n",
      "Epoch 418/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.4642e-04 - iou_score: 0.9932 - val_loss: 0.0013 - val_iou_score: 0.9098\n",
      "Epoch 419/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.2697e-04 - iou_score: 0.9936 - val_loss: 0.0012 - val_iou_score: 0.9108\n",
      "Epoch 420/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9163e-04 - iou_score: 0.9941 - val_loss: 0.0014 - val_iou_score: 0.9099\n",
      "Epoch 421/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.1140e-04 - iou_score: 0.9905 - val_loss: 0.0016 - val_iou_score: 0.9043\n",
      "Epoch 422/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.3798e-04 - iou_score: 0.9885 - val_loss: 0.0012 - val_iou_score: 0.9088\n",
      "Epoch 423/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.7645e-04 - iou_score: 0.9919 - val_loss: 0.0013 - val_iou_score: 0.9090\n",
      "Epoch 424/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.3195e-04 - iou_score: 0.9907 - val_loss: 0.0014 - val_iou_score: 0.9076\n",
      "Epoch 425/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.9713e-04 - iou_score: 0.9919 - val_loss: 0.0013 - val_iou_score: 0.9093\n",
      "Epoch 426/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8264e-04 - iou_score: 0.9918 - val_loss: 0.0016 - val_iou_score: 0.9057\n",
      "Epoch 427/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.5927e-04 - iou_score: 0.9886 - val_loss: 0.0015 - val_iou_score: 0.9067\n",
      "Epoch 428/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.9584e-04 - iou_score: 0.9918 - val_loss: 0.0012 - val_iou_score: 0.9097\n",
      "Epoch 429/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.1929e-04 - iou_score: 0.9932 - val_loss: 0.0012 - val_iou_score: 0.9109\n",
      "Epoch 430/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5471e-04 - iou_score: 0.9930 - val_loss: 0.0017 - val_iou_score: 0.9055\n",
      "Epoch 431/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.7459e-04 - iou_score: 0.9856 - val_loss: 0.0020 - val_iou_score: 0.8992\n",
      "Epoch 432/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.4325e-04 - iou_score: 0.9876 - val_loss: 0.0012 - val_iou_score: 0.9102\n",
      "Epoch 433/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.0671e-04 - iou_score: 0.9936 - val_loss: 0.0012 - val_iou_score: 0.9109\n",
      "Epoch 434/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 1.7385e-04 - iou_score: 0.9944 - val_loss: 0.0013 - val_iou_score: 0.9095\n",
      "Epoch 435/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.1116e-04 - iou_score: 0.9938 - val_loss: 0.0013 - val_iou_score: 0.9110\n",
      "Epoch 436/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.9117e-04 - iou_score: 0.9943 - val_loss: 0.0016 - val_iou_score: 0.9081\n",
      "Epoch 437/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.7779e-04 - iou_score: 0.9946 - val_loss: 0.0014 - val_iou_score: 0.9108\n",
      "Epoch 438/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9282e-04 - iou_score: 0.9944 - val_loss: 0.0014 - val_iou_score: 0.9118\n",
      "Epoch 439/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.4715e-04 - iou_score: 0.9931 - val_loss: 0.0016 - val_iou_score: 0.9084\n",
      "Epoch 440/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.2669e-04 - iou_score: 0.9917 - val_loss: 0.0017 - val_iou_score: 0.9063\n",
      "Epoch 441/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 0.0013 - iou_score: 0.9621 - val_loss: 0.0014 - val_iou_score: 0.9013\n",
      "Epoch 442/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.7560e-04 - iou_score: 0.9885 - val_loss: 0.0012 - val_iou_score: 0.9081\n",
      "Epoch 443/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8876e-04 - iou_score: 0.9918 - val_loss: 0.0012 - val_iou_score: 0.9092\n",
      "Epoch 444/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5849e-04 - iou_score: 0.9927 - val_loss: 0.0014 - val_iou_score: 0.9077\n",
      "Epoch 445/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.0364e-04 - iou_score: 0.9939 - val_loss: 0.0012 - val_iou_score: 0.9106\n",
      "Epoch 446/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.2537e-04 - iou_score: 0.9939 - val_loss: 0.0013 - val_iou_score: 0.9107\n",
      "Epoch 447/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5713e-04 - iou_score: 0.9932 - val_loss: 0.0014 - val_iou_score: 0.9101\n",
      "Epoch 448/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.5827e-04 - iou_score: 0.9929 - val_loss: 0.0014 - val_iou_score: 0.9096\n",
      "Epoch 449/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.4347e-04 - iou_score: 0.9931 - val_loss: 0.0013 - val_iou_score: 0.9109\n",
      "Epoch 450/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.6436e-04 - iou_score: 0.9866 - val_loss: 0.0013 - val_iou_score: 0.9063\n",
      "Epoch 451/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.8432e-04 - iou_score: 0.9860 - val_loss: 0.0011 - val_iou_score: 0.9090\n",
      "Epoch 452/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.0631e-04 - iou_score: 0.9932 - val_loss: 0.0012 - val_iou_score: 0.9100\n",
      "Epoch 453/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.5272e-04 - iou_score: 0.9952 - val_loss: 0.0013 - val_iou_score: 0.9111\n",
      "Epoch 454/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4908e-04 - iou_score: 0.9955 - val_loss: 0.0012 - val_iou_score: 0.9122\n",
      "Epoch 455/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.4722e-04 - iou_score: 0.9955 - val_loss: 0.0013 - val_iou_score: 0.9120\n",
      "Epoch 456/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.8133e-04 - iou_score: 0.9946 - val_loss: 0.0013 - val_iou_score: 0.9127\n",
      "Epoch 457/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.5336e-04 - iou_score: 0.9955 - val_loss: 0.0013 - val_iou_score: 0.9120\n",
      "Epoch 458/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.6740e-04 - iou_score: 0.9953 - val_loss: 0.0014 - val_iou_score: 0.9113\n",
      "Epoch 459/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.1390e-04 - iou_score: 0.9941 - val_loss: 0.0015 - val_iou_score: 0.9089\n",
      "Epoch 460/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.7132e-04 - iou_score: 0.9803 - val_loss: 0.0015 - val_iou_score: 0.9086\n",
      "Epoch 461/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.1317e-04 - iou_score: 0.9918 - val_loss: 0.0014 - val_iou_score: 0.9102\n",
      "Epoch 462/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.1656e-04 - iou_score: 0.9939 - val_loss: 0.0013 - val_iou_score: 0.9113\n",
      "Epoch 463/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.8165e-04 - iou_score: 0.9949 - val_loss: 0.0013 - val_iou_score: 0.9108\n",
      "Epoch 464/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.7815e-04 - iou_score: 0.9927 - val_loss: 0.0015 - val_iou_score: 0.9076\n",
      "Epoch 465/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.3687e-04 - iou_score: 0.9933 - val_loss: 0.0012 - val_iou_score: 0.9121\n",
      "Epoch 466/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.3268e-04 - iou_score: 0.9957 - val_loss: 0.0013 - val_iou_score: 0.9130\n",
      "Epoch 467/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.2764e-04 - iou_score: 0.9960 - val_loss: 0.0013 - val_iou_score: 0.9126\n",
      "Epoch 468/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.6396e-04 - iou_score: 0.9954 - val_loss: 0.0014 - val_iou_score: 0.9118\n",
      "Epoch 469/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4729e-04 - iou_score: 0.9959 - val_loss: 0.0014 - val_iou_score: 0.9130\n",
      "Epoch 470/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.8166e-04 - iou_score: 0.9952 - val_loss: 0.0018 - val_iou_score: 0.9082\n",
      "Epoch 471/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.0614e-04 - iou_score: 0.9925 - val_loss: 0.0016 - val_iou_score: 0.9084\n",
      "Epoch 472/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.5322e-04 - iou_score: 0.9917 - val_loss: 0.0015 - val_iou_score: 0.9093\n",
      "Epoch 473/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.9070e-04 - iou_score: 0.9924 - val_loss: 0.0014 - val_iou_score: 0.9093\n",
      "Epoch 474/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.7578e-04 - iou_score: 0.9947 - val_loss: 0.0013 - val_iou_score: 0.9120\n",
      "Epoch 475/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.6181e-04 - iou_score: 0.9953 - val_loss: 0.0014 - val_iou_score: 0.9124\n",
      "Epoch 476/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.7715e-04 - iou_score: 0.9927 - val_loss: 0.0018 - val_iou_score: 0.9041\n",
      "Epoch 477/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.7613e-04 - iou_score: 0.9921 - val_loss: 0.0014 - val_iou_score: 0.9117\n",
      "Epoch 478/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.4613e-04 - iou_score: 0.9824 - val_loss: 0.0014 - val_iou_score: 0.9106\n",
      "Epoch 479/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5485e-04 - iou_score: 0.9932 - val_loss: 0.0015 - val_iou_score: 0.9092\n",
      "Epoch 480/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.6067e-04 - iou_score: 0.9926 - val_loss: 0.0013 - val_iou_score: 0.9106\n",
      "Epoch 481/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.4752e-04 - iou_score: 0.9954 - val_loss: 0.0014 - val_iou_score: 0.9121\n",
      "Epoch 482/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.3104e-04 - iou_score: 0.9959 - val_loss: 0.0015 - val_iou_score: 0.9105\n",
      "Epoch 483/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.7354e-04 - iou_score: 0.9835 - val_loss: 0.0014 - val_iou_score: 0.9135\n",
      "Epoch 484/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.1483e-04 - iou_score: 0.9966 - val_loss: 0.0014 - val_iou_score: 0.9138\n",
      "Epoch 485/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.6983e-04 - iou_score: 0.9940 - val_loss: 0.0019 - val_iou_score: 0.9106\n",
      "Epoch 486/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8166e-04 - iou_score: 0.9926 - val_loss: 0.0013 - val_iou_score: 0.9127\n",
      "Epoch 487/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.8066e-04 - iou_score: 0.9948 - val_loss: 0.0014 - val_iou_score: 0.9114\n",
      "Epoch 488/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 4.1455e-04 - iou_score: 0.9913 - val_loss: 0.0014 - val_iou_score: 0.9094\n",
      "Epoch 489/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 2.5821e-04 - iou_score: 0.9815 - val_loss: 0.0016 - val_iou_score: 0.9065\n",
      "Epoch 490/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.9983e-04 - iou_score: 0.9944 - val_loss: 0.0015 - val_iou_score: 0.9085\n",
      "Epoch 491/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.5493e-04 - iou_score: 0.9749 - val_loss: 0.0022 - val_iou_score: 0.8994\n",
      "Epoch 492/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.1750e-04 - iou_score: 0.9861 - val_loss: 0.0013 - val_iou_score: 0.9075\n",
      "Epoch 493/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 1.8033e-04 - iou_score: 0.9941 - val_loss: 0.0012 - val_iou_score: 0.9104\n",
      "Epoch 494/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.1960e-04 - iou_score: 0.9962 - val_loss: 0.0011 - val_iou_score: 0.9136\n",
      "Epoch 495/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.5902e-05 - iou_score: 0.9969 - val_loss: 0.0013 - val_iou_score: 0.9140\n",
      "Epoch 496/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.4894e-05 - iou_score: 0.9971 - val_loss: 0.0013 - val_iou_score: 0.9137\n",
      "Epoch 497/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.0335e-05 - iou_score: 0.9861 - val_loss: 0.0014 - val_iou_score: 0.9136\n",
      "Epoch 498/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.1350e-04 - iou_score: 0.9856 - val_loss: 0.0014 - val_iou_score: 0.9127\n",
      "Epoch 499/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.3155e-04 - iou_score: 0.9961 - val_loss: 0.0016 - val_iou_score: 0.9106\n",
      "Epoch 500/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.5506e-04 - iou_score: 0.9843 - val_loss: 0.0015 - val_iou_score: 0.9119\n",
      "Epoch 501/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.5013e-04 - iou_score: 0.9956 - val_loss: 0.0015 - val_iou_score: 0.9128\n",
      "Epoch 502/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.5999e-04 - iou_score: 0.9844 - val_loss: 0.0018 - val_iou_score: 0.9116\n",
      "Epoch 503/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.6361e-04 - iou_score: 0.9884 - val_loss: 0.0018 - val_iou_score: 0.9067\n",
      "Epoch 504/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.2522e-04 - iou_score: 0.9913 - val_loss: 0.0019 - val_iou_score: 0.9074\n",
      "Epoch 505/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 0.0011 - iou_score: 0.9792 - val_loss: 0.0018 - val_iou_score: 0.9011\n",
      "Epoch 506/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.5071e-04 - iou_score: 0.9889 - val_loss: 0.0020 - val_iou_score: 0.9021\n",
      "Epoch 507/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.7283e-04 - iou_score: 0.9902 - val_loss: 0.0011 - val_iou_score: 0.9099\n",
      "Epoch 508/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.6596e-04 - iou_score: 0.9949 - val_loss: 0.0010 - val_iou_score: 0.9130\n",
      "Epoch 509/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.1619e-04 - iou_score: 0.9963 - val_loss: 0.0011 - val_iou_score: 0.9134\n",
      "Epoch 510/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.2117e-04 - iou_score: 0.9963 - val_loss: 0.0012 - val_iou_score: 0.9136\n",
      "Epoch 511/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0330e-04 - iou_score: 0.9968 - val_loss: 0.0012 - val_iou_score: 0.9141\n",
      "Epoch 512/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.2387e-04 - iou_score: 0.9965 - val_loss: 0.0013 - val_iou_score: 0.9134\n",
      "Epoch 513/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 1.4466e-04 - iou_score: 0.9958 - val_loss: 0.0013 - val_iou_score: 0.9134\n",
      "Epoch 514/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 1.4969e-04 - iou_score: 0.9958 - val_loss: 0.0013 - val_iou_score: 0.9138\n",
      "Epoch 515/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9210e-04 - iou_score: 0.9947 - val_loss: 0.0016 - val_iou_score: 0.9093\n",
      "Epoch 516/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.9096e-04 - iou_score: 0.9928 - val_loss: 0.0013 - val_iou_score: 0.9121\n",
      "Epoch 517/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.1008e-04 - iou_score: 0.9944 - val_loss: 0.0014 - val_iou_score: 0.9150\n",
      "Epoch 518/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.2829e-04 - iou_score: 0.9960 - val_loss: 0.0012 - val_iou_score: 0.9143\n",
      "Epoch 519/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.9166e-05 - iou_score: 0.9969 - val_loss: 0.0013 - val_iou_score: 0.9137\n",
      "Epoch 520/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.9811e-05 - iou_score: 0.9970 - val_loss: 0.0013 - val_iou_score: 0.9145\n",
      "Epoch 521/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0052e-04 - iou_score: 0.9971 - val_loss: 0.0013 - val_iou_score: 0.9156\n",
      "Epoch 522/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.1926e-04 - iou_score: 0.9968 - val_loss: 0.0013 - val_iou_score: 0.9142\n",
      "Epoch 523/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0737e-04 - iou_score: 0.9970 - val_loss: 0.0014 - val_iou_score: 0.9150\n",
      "Epoch 524/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.4983e-04 - iou_score: 0.9962 - val_loss: 0.0013 - val_iou_score: 0.9149\n",
      "Epoch 525/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.8282e-04 - iou_score: 0.9950 - val_loss: 0.0013 - val_iou_score: 0.9127\n",
      "Epoch 526/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.4766e-04 - iou_score: 0.9959 - val_loss: 0.0014 - val_iou_score: 0.9124\n",
      "Epoch 527/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4528e-04 - iou_score: 0.9961 - val_loss: 0.0014 - val_iou_score: 0.9121\n",
      "Epoch 528/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.0793e-04 - iou_score: 0.9949 - val_loss: 0.0015 - val_iou_score: 0.9102\n",
      "Epoch 529/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.7223e-04 - iou_score: 0.9920 - val_loss: 0.0014 - val_iou_score: 0.9097\n",
      "Epoch 530/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5714e-04 - iou_score: 0.9935 - val_loss: 0.0013 - val_iou_score: 0.9109\n",
      "Epoch 531/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.1561e-04 - iou_score: 0.9943 - val_loss: 0.0012 - val_iou_score: 0.9125\n",
      "Epoch 532/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.1456e-04 - iou_score: 0.9963 - val_loss: 0.0012 - val_iou_score: 0.9147\n",
      "Epoch 533/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.8357e-05 - iou_score: 0.9973 - val_loss: 0.0012 - val_iou_score: 0.9150\n",
      "Epoch 534/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.4337e-05 - iou_score: 0.9977 - val_loss: 0.0013 - val_iou_score: 0.9148\n",
      "Epoch 535/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.5602e-05 - iou_score: 0.9977 - val_loss: 0.0013 - val_iou_score: 0.9150\n",
      "Epoch 536/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.6039e-05 - iou_score: 0.9972 - val_loss: 0.0013 - val_iou_score: 0.9141\n",
      "Epoch 537/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.9035e-04 - iou_score: 0.9935 - val_loss: 0.0015 - val_iou_score: 0.9091\n",
      "Epoch 538/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.4560e-04 - iou_score: 0.9928 - val_loss: 0.0014 - val_iou_score: 0.9131\n",
      "Epoch 539/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0953e-04 - iou_score: 0.9964 - val_loss: 0.0013 - val_iou_score: 0.9139\n",
      "Epoch 540/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.0651e-04 - iou_score: 0.9968 - val_loss: 0.0013 - val_iou_score: 0.9138\n",
      "Epoch 541/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4294e-04 - iou_score: 0.9961 - val_loss: 0.0014 - val_iou_score: 0.9150\n",
      "Epoch 542/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0540e-04 - iou_score: 0.9971 - val_loss: 0.0016 - val_iou_score: 0.9128\n",
      "Epoch 543/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.6500e-04 - iou_score: 0.9849 - val_loss: 0.0015 - val_iou_score: 0.9118\n",
      "Epoch 544/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.4333e-04 - iou_score: 0.9922 - val_loss: 0.0015 - val_iou_score: 0.9090\n",
      "Epoch 545/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.7511e-04 - iou_score: 0.9925 - val_loss: 0.0015 - val_iou_score: 0.9087\n",
      "Epoch 546/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9271e-04 - iou_score: 0.9947 - val_loss: 0.0013 - val_iou_score: 0.9121\n",
      "Epoch 547/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.3652e-04 - iou_score: 0.9961 - val_loss: 0.0013 - val_iou_score: 0.9144\n",
      "Epoch 548/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.7223e-05 - iou_score: 0.9978 - val_loss: 0.0012 - val_iou_score: 0.9157\n",
      "Epoch 549/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.1086e-05 - iou_score: 0.9982 - val_loss: 0.0013 - val_iou_score: 0.9150\n",
      "Epoch 550/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.7334e-05 - iou_score: 0.9974 - val_loss: 0.0015 - val_iou_score: 0.9148\n",
      "Epoch 551/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.6037e-04 - iou_score: 0.9942 - val_loss: 0.0015 - val_iou_score: 0.9104\n",
      "Epoch 552/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.3860e-04 - iou_score: 0.9936 - val_loss: 0.0012 - val_iou_score: 0.9142\n",
      "Epoch 553/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.7334e-05 - iou_score: 0.9977 - val_loss: 0.0013 - val_iou_score: 0.9151\n",
      "Epoch 554/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.0375e-05 - iou_score: 0.9981 - val_loss: 0.0013 - val_iou_score: 0.9145\n",
      "Epoch 555/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.2846e-04 - iou_score: 0.9968 - val_loss: 0.0015 - val_iou_score: 0.9139\n",
      "Epoch 556/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.2919e-04 - iou_score: 0.9967 - val_loss: 0.0015 - val_iou_score: 0.9138\n",
      "Epoch 557/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.5653e-04 - iou_score: 0.9963 - val_loss: 0.0015 - val_iou_score: 0.9126\n",
      "Epoch 558/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4770e-04 - iou_score: 0.9964 - val_loss: 0.0016 - val_iou_score: 0.9148\n",
      "Epoch 559/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9624e-04 - iou_score: 0.9954 - val_loss: 0.0017 - val_iou_score: 0.9100\n",
      "Epoch 560/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.6753e-04 - iou_score: 0.9828 - val_loss: 0.0014 - val_iou_score: 0.9110\n",
      "Epoch 561/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4692e-04 - iou_score: 0.9958 - val_loss: 0.0014 - val_iou_score: 0.9119\n",
      "Epoch 562/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.6646e-04 - iou_score: 0.9954 - val_loss: 0.0013 - val_iou_score: 0.9134\n",
      "Epoch 563/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.1457e-04 - iou_score: 0.9966 - val_loss: 0.0013 - val_iou_score: 0.9160\n",
      "Epoch 564/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.1085e-04 - iou_score: 0.9970 - val_loss: 0.0015 - val_iou_score: 0.9123\n",
      "Epoch 565/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.3846e-04 - iou_score: 0.9960 - val_loss: 0.0014 - val_iou_score: 0.9133\n",
      "Epoch 566/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4000e-04 - iou_score: 0.9962 - val_loss: 0.0013 - val_iou_score: 0.9137\n",
      "Epoch 567/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0471e-04 - iou_score: 0.9970 - val_loss: 0.0013 - val_iou_score: 0.9151\n",
      "Epoch 568/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.9554e-05 - iou_score: 0.9975 - val_loss: 0.0015 - val_iou_score: 0.9149\n",
      "Epoch 569/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.5087e-05 - iou_score: 0.9983 - val_loss: 0.0014 - val_iou_score: 0.9172\n",
      "Epoch 570/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.6749e-04 - iou_score: 0.9964 - val_loss: 0.0017 - val_iou_score: 0.9136\n",
      "Epoch 571/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.4756e-04 - iou_score: 0.9925 - val_loss: 0.0019 - val_iou_score: 0.9094\n",
      "Epoch 572/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.3587e-04 - iou_score: 0.9919 - val_loss: 0.0012 - val_iou_score: 0.9135\n",
      "Epoch 573/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.6963e-04 - iou_score: 0.9935 - val_loss: 0.0012 - val_iou_score: 0.9115\n",
      "Epoch 574/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4641e-04 - iou_score: 0.9954 - val_loss: 0.0014 - val_iou_score: 0.9102\n",
      "Epoch 575/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.3918e-04 - iou_score: 0.9960 - val_loss: 0.0013 - val_iou_score: 0.9142\n",
      "Epoch 576/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 5.5489e-05 - iou_score: 0.9981 - val_loss: 0.0013 - val_iou_score: 0.9155\n",
      "Epoch 577/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.1698e-05 - iou_score: 0.9985 - val_loss: 0.0014 - val_iou_score: 0.9157\n",
      "Epoch 578/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.8026e-05 - iou_score: 0.9988 - val_loss: 0.0014 - val_iou_score: 0.9156\n",
      "Epoch 579/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.6913e-05 - iou_score: 0.9988 - val_loss: 0.0014 - val_iou_score: 0.9162\n",
      "Epoch 580/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.6489e-05 - iou_score: 0.9875 - val_loss: 0.0015 - val_iou_score: 0.9148\n",
      "Epoch 581/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 7.1368e-05 - iou_score: 0.9980 - val_loss: 0.0015 - val_iou_score: 0.9140\n",
      "Epoch 582/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 9.5458e-05 - iou_score: 0.9863 - val_loss: 0.0015 - val_iou_score: 0.9137\n",
      "Epoch 583/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9733e-04 - iou_score: 0.9955 - val_loss: 0.0018 - val_iou_score: 0.9095\n",
      "Epoch 584/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8165e-04 - iou_score: 0.9938 - val_loss: 0.0020 - val_iou_score: 0.9075\n",
      "Epoch 585/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.8429e-04 - iou_score: 0.9756 - val_loss: 0.0016 - val_iou_score: 0.9070\n",
      "Epoch 586/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9889e-04 - iou_score: 0.9939 - val_loss: 0.0012 - val_iou_score: 0.9122\n",
      "Epoch 587/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.4989e-04 - iou_score: 0.9944 - val_loss: 0.0013 - val_iou_score: 0.9121\n",
      "Epoch 588/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.3156e-04 - iou_score: 0.9962 - val_loss: 0.0012 - val_iou_score: 0.9138\n",
      "Epoch 589/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.4363e-05 - iou_score: 0.9979 - val_loss: 0.0012 - val_iou_score: 0.9152\n",
      "Epoch 590/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.0299e-05 - iou_score: 0.9986 - val_loss: 0.0012 - val_iou_score: 0.9168\n",
      "Epoch 591/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.2950e-05 - iou_score: 0.9988 - val_loss: 0.0013 - val_iou_score: 0.9160\n",
      "Epoch 592/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.2048e-05 - iou_score: 0.9990 - val_loss: 0.0013 - val_iou_score: 0.9167\n",
      "Epoch 593/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.5024e-05 - iou_score: 0.9989 - val_loss: 0.0014 - val_iou_score: 0.9173\n",
      "Epoch 594/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.0140e-05 - iou_score: 0.9991 - val_loss: 0.0014 - val_iou_score: 0.9199\n",
      "Epoch 595/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.8540e-05 - iou_score: 0.9984 - val_loss: 0.0016 - val_iou_score: 0.9267\n",
      "Epoch 596/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.3188e-04 - iou_score: 0.9857 - val_loss: 0.0016 - val_iou_score: 0.9116\n",
      "Epoch 597/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.9755e-04 - iou_score: 0.9708 - val_loss: 0.0014 - val_iou_score: 0.9107\n",
      "Epoch 598/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.5636e-04 - iou_score: 0.9954 - val_loss: 0.0013 - val_iou_score: 0.9140\n",
      "Epoch 599/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.1174e-05 - iou_score: 0.9864 - val_loss: 0.0013 - val_iou_score: 0.9171\n",
      "Epoch 600/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.8570e-05 - iou_score: 0.9980 - val_loss: 0.0014 - val_iou_score: 0.9190\n",
      "Epoch 601/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.1315e-04 - iou_score: 0.9959 - val_loss: 0.0015 - val_iou_score: 0.9179\n",
      "Epoch 602/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.2821e-04 - iou_score: 0.9947 - val_loss: 0.0013 - val_iou_score: 0.9152\n",
      "Epoch 603/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.1459e-04 - iou_score: 0.9968 - val_loss: 0.0012 - val_iou_score: 0.9148\n",
      "Epoch 604/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.6898e-05 - iou_score: 0.9980 - val_loss: 0.0013 - val_iou_score: 0.9154\n",
      "Epoch 605/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 5.2022e-05 - iou_score: 0.9986 - val_loss: 0.0013 - val_iou_score: 0.9207\n",
      "Epoch 606/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.6754e-05 - iou_score: 0.9987 - val_loss: 0.0014 - val_iou_score: 0.9196\n",
      "Epoch 607/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 7.9021e-05 - iou_score: 0.9980 - val_loss: 0.0014 - val_iou_score: 0.9158\n",
      "Epoch 608/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 1.5992e-04 - iou_score: 0.9964 - val_loss: 0.0016 - val_iou_score: 0.9127\n",
      "Epoch 609/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.4910e-04 - iou_score: 0.9939 - val_loss: 0.0014 - val_iou_score: 0.9126\n",
      "Epoch 610/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.4658e-04 - iou_score: 0.9957 - val_loss: 0.0015 - val_iou_score: 0.9127\n",
      "Epoch 611/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.3621e-04 - iou_score: 0.9963 - val_loss: 0.0016 - val_iou_score: 0.9168\n",
      "Epoch 612/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.1820e-04 - iou_score: 0.9967 - val_loss: 0.0013 - val_iou_score: 0.9140\n",
      "Epoch 613/1400\n",
      "89/89 [==============================] - 22s 252ms/step - loss: 9.2327e-05 - iou_score: 0.9973 - val_loss: 0.0014 - val_iou_score: 0.9158\n",
      "Epoch 614/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.2542e-05 - iou_score: 0.9983 - val_loss: 0.0014 - val_iou_score: 0.9158\n",
      "Epoch 615/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.1499e-05 - iou_score: 0.9986 - val_loss: 0.0014 - val_iou_score: 0.9157\n",
      "Epoch 616/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.5353e-05 - iou_score: 0.9989 - val_loss: 0.0015 - val_iou_score: 0.9171\n",
      "Epoch 617/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.1596e-04 - iou_score: 0.9972 - val_loss: 0.0016 - val_iou_score: 0.9152\n",
      "Epoch 618/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4223e-04 - iou_score: 0.9962 - val_loss: 0.0017 - val_iou_score: 0.9124\n",
      "Epoch 619/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.0868e-04 - iou_score: 0.9949 - val_loss: 0.0015 - val_iou_score: 0.9128\n",
      "Epoch 620/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.6199e-04 - iou_score: 0.9960 - val_loss: 0.0015 - val_iou_score: 0.9140\n",
      "Epoch 621/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.5096e-04 - iou_score: 0.9894 - val_loss: 0.0015 - val_iou_score: 0.9096\n",
      "Epoch 622/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.1418e-04 - iou_score: 0.9941 - val_loss: 0.0014 - val_iou_score: 0.9107\n",
      "Epoch 623/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.0679e-05 - iou_score: 0.9974 - val_loss: 0.0012 - val_iou_score: 0.9151\n",
      "Epoch 624/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.8288e-05 - iou_score: 0.9987 - val_loss: 0.0012 - val_iou_score: 0.9163\n",
      "Epoch 625/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.4511e-05 - iou_score: 0.9991 - val_loss: 0.0012 - val_iou_score: 0.9171\n",
      "Epoch 626/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.2132e-05 - iou_score: 0.9880 - val_loss: 0.0013 - val_iou_score: 0.9168\n",
      "Epoch 627/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.4342e-05 - iou_score: 0.9993 - val_loss: 0.0013 - val_iou_score: 0.9166\n",
      "Epoch 628/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.8381e-05 - iou_score: 0.9990 - val_loss: 0.0014 - val_iou_score: 0.9161\n",
      "Epoch 629/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.8752e-05 - iou_score: 0.9987 - val_loss: 0.0015 - val_iou_score: 0.9152\n",
      "Epoch 630/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.5268e-04 - iou_score: 0.9969 - val_loss: 0.0020 - val_iou_score: 0.9101\n",
      "Epoch 631/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.0088e-04 - iou_score: 0.9893 - val_loss: 0.0015 - val_iou_score: 0.9082\n",
      "Epoch 632/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4829e-04 - iou_score: 0.9842 - val_loss: 0.0012 - val_iou_score: 0.9150\n",
      "Epoch 633/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.6405e-05 - iou_score: 0.9975 - val_loss: 0.0012 - val_iou_score: 0.9147\n",
      "Epoch 634/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 5.1558e-05 - iou_score: 0.9983 - val_loss: 0.0013 - val_iou_score: 0.9161\n",
      "Epoch 635/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.2426e-05 - iou_score: 0.9986 - val_loss: 0.0014 - val_iou_score: 0.9165\n",
      "Epoch 636/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.9318e-05 - iou_score: 0.9981 - val_loss: 0.0016 - val_iou_score: 0.9150\n",
      "Epoch 637/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.6561e-04 - iou_score: 0.9958 - val_loss: 0.0014 - val_iou_score: 0.9143\n",
      "Epoch 638/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.7203e-05 - iou_score: 0.9976 - val_loss: 0.0014 - val_iou_score: 0.9161\n",
      "Epoch 639/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 4.5994e-05 - iou_score: 0.9985 - val_loss: 0.0015 - val_iou_score: 0.9166\n",
      "Epoch 640/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8242e-05 - iou_score: 0.9878 - val_loss: 0.0013 - val_iou_score: 0.9195\n",
      "Epoch 641/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.9348e-04 - iou_score: 0.9956 - val_loss: 0.0014 - val_iou_score: 0.9148\n",
      "Epoch 752/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.0496e-05 - iou_score: 0.9877 - val_loss: 0.0011 - val_iou_score: 0.9177\n",
      "Epoch 757/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.7384e-05 - iou_score: 0.9994 - val_loss: 0.0011 - val_iou_score: 0.9182\n",
      "Epoch 758/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.2589e-05 - iou_score: 0.9995 - val_loss: 0.0012 - val_iou_score: 0.9180\n",
      "Epoch 759/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.2334e-05 - iou_score: 0.9883 - val_loss: 0.0012 - val_iou_score: 0.9189\n",
      "Epoch 760/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.3122e-05 - iou_score: 0.9996 - val_loss: 0.0012 - val_iou_score: 0.9191\n",
      "Epoch 761/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.3397e-05 - iou_score: 0.9996 - val_loss: 0.0013 - val_iou_score: 0.9188\n",
      "Epoch 762/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.5467e-05 - iou_score: 0.9993 - val_loss: 0.0013 - val_iou_score: 0.9226\n",
      "Epoch 763/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.1570e-05 - iou_score: 0.9986 - val_loss: 0.0018 - val_iou_score: 0.9144\n",
      "Epoch 764/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 5.1356e-04 - iou_score: 0.9880 - val_loss: 0.0013 - val_iou_score: 0.9104\n",
      "Epoch 765/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.4158e-04 - iou_score: 0.9955 - val_loss: 0.0013 - val_iou_score: 0.9273\n",
      "Epoch 766/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 6.9592e-05 - iou_score: 0.9980 - val_loss: 0.0012 - val_iou_score: 0.9337\n",
      "Epoch 767/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.1773e-04 - iou_score: 0.9975 - val_loss: 0.0012 - val_iou_score: 0.9448\n",
      "Epoch 768/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.1982e-04 - iou_score: 0.9973 - val_loss: 0.0013 - val_iou_score: 0.9329\n",
      "Epoch 769/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 8.6541e-05 - iou_score: 0.9978 - val_loss: 0.0011 - val_iou_score: 0.9240\n",
      "Epoch 770/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.4759e-05 - iou_score: 0.9989 - val_loss: 0.0011 - val_iou_score: 0.9182\n",
      "Epoch 771/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.2626e-05 - iou_score: 0.9993 - val_loss: 0.0012 - val_iou_score: 0.9176\n",
      "Epoch 772/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.2610e-05 - iou_score: 0.9991 - val_loss: 0.0013 - val_iou_score: 0.9175\n",
      "Epoch 773/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 4.3942e-05 - iou_score: 0.9988 - val_loss: 0.0013 - val_iou_score: 0.9174\n",
      "Epoch 774/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.9578e-05 - iou_score: 0.9981 - val_loss: 0.0013 - val_iou_score: 0.9292\n",
      "Epoch 775/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0449e-04 - iou_score: 0.9861 - val_loss: 0.0013 - val_iou_score: 0.9335\n",
      "Epoch 776/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.2695e-04 - iou_score: 0.9946 - val_loss: 0.0013 - val_iou_score: 0.9274\n",
      "Epoch 777/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.3201e-04 - iou_score: 0.9941 - val_loss: 0.0013 - val_iou_score: 0.9285\n",
      "Epoch 778/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.1001e-04 - iou_score: 0.9972 - val_loss: 0.0012 - val_iou_score: 0.9331\n",
      "Epoch 779/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 3.7113e-05 - iou_score: 0.9989 - val_loss: 0.0012 - val_iou_score: 0.9211\n",
      "Epoch 780/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.4953e-05 - iou_score: 0.9992 - val_loss: 0.0012 - val_iou_score: 0.9183\n",
      "Epoch 781/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 1.7419e-05 - iou_score: 0.9994 - val_loss: 0.0012 - val_iou_score: 0.9176\n",
      "Epoch 782/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.2423e-05 - iou_score: 0.9996 - val_loss: 0.0012 - val_iou_score: 0.9186\n",
      "Epoch 783/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.7125e-05 - iou_score: 0.9995 - val_loss: 0.0013 - val_iou_score: 0.9295\n",
      "Epoch 784/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 3.5861e-05 - iou_score: 0.9991 - val_loss: 0.0013 - val_iou_score: 0.9171\n",
      "Epoch 785/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 6.1631e-05 - iou_score: 0.9984 - val_loss: 0.0013 - val_iou_score: 0.9196\n",
      "Epoch 786/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.3359e-04 - iou_score: 0.9957 - val_loss: 0.0016 - val_iou_score: 0.9109\n",
      "Epoch 787/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.3967e-04 - iou_score: 0.9825 - val_loss: 0.0012 - val_iou_score: 0.9270\n",
      "Epoch 788/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.4021e-04 - iou_score: 0.9965 - val_loss: 0.0012 - val_iou_score: 0.9250\n",
      "Epoch 789/1400\n",
      " 3/89 [>.............................] - ETA: 20s - loss: 9.9419e-05 - iou_score: 0.9970"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 22s 246ms/step - loss: 5.1353e-05 - iou_score: 0.9987 - val_loss: 0.0013 - val_iou_score: 0.9240\n",
      "Epoch 826/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.9584e-05 - iou_score: 0.9983 - val_loss: 0.0014 - val_iou_score: 0.9177\n",
      "Epoch 827/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0637e-04 - iou_score: 0.9977 - val_loss: 0.0014 - val_iou_score: 0.9204\n",
      "Epoch 828/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 7.7566e-05 - iou_score: 0.9983 - val_loss: 0.0013 - val_iou_score: 0.9302\n",
      "Epoch 829/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 9.9139e-05 - iou_score: 0.9978 - val_loss: 0.0015 - val_iou_score: 0.9455\n",
      "Epoch 830/1400\n",
      "89/89 [==============================] - 22s 246ms/step - loss: 2.4254e-04 - iou_score: 0.9943 - val_loss: 0.0014 - val_iou_score: 0.9382\n",
      "Epoch 831/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.0631e-04 - iou_score: 0.9966 - val_loss: 0.0012 - val_iou_score: 0.9237\n",
      "Epoch 832/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 2.8049e-05 - iou_score: 0.9990 - val_loss: 0.0012 - val_iou_score: 0.9484\n",
      "Epoch 833/1400\n",
      "89/89 [==============================] - 22s 247ms/step - loss: 1.7549e-05 - iou_score: 0.9994 - val_loss: 0.0012 - val_iou_score: 0.9504\n",
      "Epoch 834/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.1434e-05 - iou_score: 0.9881 - val_loss: 0.0012 - val_iou_score: 0.9535\n",
      "Epoch 835/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 3.3560e-05 - iou_score: 0.9991 - val_loss: 0.0014 - val_iou_score: 0.9156\n",
      "Epoch 836/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 6.6320e-05 - iou_score: 0.9983 - val_loss: 0.0013 - val_iou_score: 0.9450\n",
      "Epoch 837/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 2.2158e-04 - iou_score: 0.9958 - val_loss: 0.0038 - val_iou_score: 0.9006\n",
      "Epoch 838/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 3.9441e-04 - iou_score: 0.9911 - val_loss: 0.0012 - val_iou_score: 0.9169\n",
      "Epoch 839/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 2.0791e-04 - iou_score: 0.9961 - val_loss: 0.0023 - val_iou_score: 0.9053\n",
      "Epoch 840/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 0.0021 - iou_score: 0.9585 - val_loss: 0.0023 - val_iou_score: 0.8865\n",
      "Epoch 841/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 5.2032e-04 - iou_score: 0.9850 - val_loss: 0.0010 - val_iou_score: 0.9077\n",
      "Epoch 842/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 1.9337e-04 - iou_score: 0.9829 - val_loss: 9.9092e-04 - val_iou_score: 0.9119\n",
      "Epoch 843/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 1.1368e-04 - iou_score: 0.9963 - val_loss: 0.0010 - val_iou_score: 0.9135\n",
      "Epoch 844/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 7.6036e-05 - iou_score: 0.9976 - val_loss: 0.0011 - val_iou_score: 0.9144\n",
      "Epoch 845/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 5.9794e-05 - iou_score: 0.9981 - val_loss: 0.0011 - val_iou_score: 0.9159\n",
      "Epoch 846/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.0330e-05 - iou_score: 0.9986 - val_loss: 0.0012 - val_iou_score: 0.9161\n",
      "Epoch 847/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.5277e-05 - iou_score: 0.9988 - val_loss: 0.0012 - val_iou_score: 0.9178\n",
      "Epoch 848/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.7067e-05 - iou_score: 0.9988 - val_loss: 0.0012 - val_iou_score: 0.9168\n",
      "Epoch 849/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.7924e-05 - iou_score: 0.9991 - val_loss: 0.0013 - val_iou_score: 0.9168\n",
      "Epoch 850/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.6337e-05 - iou_score: 0.9992 - val_loss: 0.0012 - val_iou_score: 0.9221\n",
      "Epoch 851/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 2.6849e-05 - iou_score: 0.9992 - val_loss: 0.0013 - val_iou_score: 0.9193\n",
      "Epoch 852/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.4005e-05 - iou_score: 0.9989 - val_loss: 0.0014 - val_iou_score: 0.9206\n",
      "Epoch 853/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 5.9406e-05 - iou_score: 0.9872 - val_loss: 0.0013 - val_iou_score: 0.9170\n",
      "Epoch 854/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 1.1788e-04 - iou_score: 0.9973 - val_loss: 0.0014 - val_iou_score: 0.9213\n",
      "Epoch 855/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 1.0795e-04 - iou_score: 0.9973 - val_loss: 0.0012 - val_iou_score: 0.9169\n",
      "Epoch 856/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.3753e-05 - iou_score: 0.9986 - val_loss: 0.0012 - val_iou_score: 0.9180\n",
      "Epoch 857/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 2.5382e-05 - iou_score: 0.9992 - val_loss: 0.0012 - val_iou_score: 0.9182\n",
      "Epoch 858/1400\n",
      " 9/89 [==>...........................] - ETA: 19s - loss: 2.6087e-05 - iou_score: 0.9993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 22s 249ms/step - loss: 2.5219e-05 - iou_score: 0.9769 - val_loss: 0.0014 - val_iou_score: 0.9214\n",
      "Epoch 895/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 6.8144e-05 - iou_score: 0.9986 - val_loss: 0.0015 - val_iou_score: 0.9149\n",
      "Epoch 896/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.6119e-04 - iou_score: 0.9952 - val_loss: 0.0025 - val_iou_score: 0.9014\n",
      "Epoch 897/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 2.6167e-04 - iou_score: 0.9930 - val_loss: 0.0012 - val_iou_score: 0.9158\n",
      "Epoch 898/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 5.0133e-05 - iou_score: 0.9982 - val_loss: 0.0012 - val_iou_score: 0.9290\n",
      "Epoch 899/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 2.3300e-05 - iou_score: 0.9992 - val_loss: 0.0012 - val_iou_score: 0.9254\n",
      "Epoch 900/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 1.3416e-05 - iou_score: 0.9995 - val_loss: 0.0013 - val_iou_score: 0.9446\n",
      "Epoch 901/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 9.2378e-06 - iou_score: 0.9997 - val_loss: 0.0013 - val_iou_score: 0.9339\n",
      "Epoch 902/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 8.1683e-06 - iou_score: 0.9997 - val_loss: 0.0013 - val_iou_score: 0.9448\n",
      "Epoch 903/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 8.3535e-06 - iou_score: 0.9998 - val_loss: 0.0014 - val_iou_score: 0.9507\n",
      "Epoch 904/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 1.5068e-05 - iou_score: 0.9996 - val_loss: 0.0015 - val_iou_score: 0.9514\n",
      "Epoch 905/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.1549e-05 - iou_score: 0.9995 - val_loss: 0.0015 - val_iou_score: 0.9625\n",
      "Epoch 906/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 6.9292e-05 - iou_score: 0.9988 - val_loss: 0.0018 - val_iou_score: 0.9540\n",
      "Epoch 907/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.8940e-04 - iou_score: 0.9938 - val_loss: 0.0017 - val_iou_score: 0.9098\n",
      "Epoch 908/1400\n",
      "89/89 [==============================] - 22s 253ms/step - loss: 1.8716e-04 - iou_score: 0.9942 - val_loss: 0.0013 - val_iou_score: 0.9157\n",
      "Epoch 909/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 4.5716e-05 - iou_score: 0.9985 - val_loss: 0.0014 - val_iou_score: 0.9208\n",
      "Epoch 910/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.0152e-05 - iou_score: 0.9990 - val_loss: 0.0014 - val_iou_score: 0.9241\n",
      "Epoch 911/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.7930e-05 - iou_score: 0.9991 - val_loss: 0.0014 - val_iou_score: 0.9440\n",
      "Epoch 912/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 3.1385e-05 - iou_score: 0.9992 - val_loss: 0.0016 - val_iou_score: 0.9574\n",
      "Epoch 913/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 7.6275e-05 - iou_score: 0.9983 - val_loss: 0.0016 - val_iou_score: 0.9420\n",
      "Epoch 914/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 6.7912e-05 - iou_score: 0.9984 - val_loss: 0.0016 - val_iou_score: 0.9566\n",
      "Epoch 915/1400\n",
      "89/89 [==============================] - 22s 252ms/step - loss: 5.9519e-05 - iou_score: 0.9984 - val_loss: 0.0014 - val_iou_score: 0.9572\n",
      "Epoch 916/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 1.1176e-04 - iou_score: 0.9976 - val_loss: 0.0018 - val_iou_score: 0.9312\n",
      "Epoch 917/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 1.4040e-04 - iou_score: 0.9969 - val_loss: 0.0013 - val_iou_score: 0.9341\n",
      "Epoch 918/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 7.4857e-05 - iou_score: 0.9982 - val_loss: 0.0014 - val_iou_score: 0.9231\n",
      "Epoch 919/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 8.2899e-05 - iou_score: 0.9982 - val_loss: 0.0015 - val_iou_score: 0.9154\n",
      "Epoch 920/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 7.5806e-05 - iou_score: 0.9984 - val_loss: 0.0013 - val_iou_score: 0.9200\n",
      "Epoch 921/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 3.6934e-05 - iou_score: 0.9991 - val_loss: 0.0014 - val_iou_score: 0.9383\n",
      "Epoch 922/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 4.4550e-05 - iou_score: 0.9990 - val_loss: 0.0014 - val_iou_score: 0.9166\n",
      "Epoch 923/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 3.8822e-05 - iou_score: 0.9990 - val_loss: 0.0014 - val_iou_score: 0.9177\n",
      "Epoch 924/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.8822e-05 - iou_score: 0.9993 - val_loss: 0.0014 - val_iou_score: 0.9205\n",
      "Epoch 925/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 3.6677e-05 - iou_score: 0.9992 - val_loss: 0.0013 - val_iou_score: 0.9296\n",
      "Epoch 926/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 3.6121e-05 - iou_score: 0.9991 - val_loss: 0.0015 - val_iou_score: 0.9256\n",
      "Epoch 927/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 7.5525e-05 - iou_score: 0.9982 - val_loss: 0.0015 - val_iou_score: 0.9217\n",
      "Epoch 928/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 1.3775e-04 - iou_score: 0.9861 - val_loss: 0.0015 - val_iou_score: 0.9187\n",
      "Epoch 929/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 9.6447e-05 - iou_score: 0.9972 - val_loss: 0.0013 - val_iou_score: 0.9209\n",
      "Epoch 930/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.9490e-05 - iou_score: 0.9985 - val_loss: 0.0014 - val_iou_score: 0.9238\n",
      "Epoch 931/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.7360e-05 - iou_score: 0.9875 - val_loss: 0.0014 - val_iou_score: 0.9388\n",
      "Epoch 932/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 3.4649e-05 - iou_score: 0.9990 - val_loss: 0.0014 - val_iou_score: 0.9243\n",
      "Epoch 933/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 8.1597e-05 - iou_score: 0.9980 - val_loss: 0.0017 - val_iou_score: 0.9546\n",
      "Epoch 934/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 1.2009e-04 - iou_score: 0.9969 - val_loss: 0.0014 - val_iou_score: 0.9208\n",
      "Epoch 935/1400\n",
      "89/89 [==============================] - 22s 251ms/step - loss: 3.1559e-05 - iou_score: 0.9990 - val_loss: 0.0013 - val_iou_score: 0.9235\n",
      "Epoch 936/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.5746e-05 - iou_score: 0.9989 - val_loss: 0.0014 - val_iou_score: 0.9191\n",
      "Epoch 937/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.9604e-05 - iou_score: 0.9988 - val_loss: 0.0014 - val_iou_score: 0.9316\n",
      "Epoch 938/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 2.7916e-05 - iou_score: 0.9992 - val_loss: 0.0014 - val_iou_score: 0.9249\n",
      "Epoch 939/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.4211e-05 - iou_score: 0.9991 - val_loss: 0.0014 - val_iou_score: 0.9238\n",
      "Epoch 940/1400\n",
      "89/89 [==============================] - 22s 248ms/step - loss: 2.4983e-05 - iou_score: 0.9994 - val_loss: 0.0015 - val_iou_score: 0.9425\n",
      "Epoch 941/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.0731e-05 - iou_score: 0.9882 - val_loss: 0.0015 - val_iou_score: 0.9552\n",
      "Epoch 942/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 5.1728e-05 - iou_score: 0.9991 - val_loss: 0.0016 - val_iou_score: 0.9316\n",
      "Epoch 943/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.5880e-04 - iou_score: 0.9940 - val_loss: 0.0013 - val_iou_score: 0.9305\n",
      "Epoch 944/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 8.3338e-05 - iou_score: 0.9977 - val_loss: 0.0013 - val_iou_score: 0.9235\n",
      "Epoch 945/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.7059e-05 - iou_score: 0.9988 - val_loss: 0.0011 - val_iou_score: 0.9219\n",
      "Epoch 946/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 1.8721e-05 - iou_score: 0.9994 - val_loss: 0.0012 - val_iou_score: 0.9184\n",
      "Epoch 947/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 2.0082e-05 - iou_score: 0.9994 - val_loss: 0.0014 - val_iou_score: 0.9170\n",
      "Epoch 948/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 3.8545e-04 - iou_score: 0.9924 - val_loss: 0.0012 - val_iou_score: 0.9133\n",
      "Epoch 949/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 1.1535e-04 - iou_score: 0.9963 - val_loss: 0.0010 - val_iou_score: 0.9358\n",
      "Epoch 950/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 2.7602e-05 - iou_score: 0.9990 - val_loss: 0.0011 - val_iou_score: 0.9261\n",
      "Epoch 951/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 1.1253e-05 - iou_score: 0.9995 - val_loss: 0.0011 - val_iou_score: 0.9284\n",
      "Epoch 952/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 6.5921e-06 - iou_score: 0.9885 - val_loss: 0.0012 - val_iou_score: 0.9244\n",
      "Epoch 953/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 5.6155e-06 - iou_score: 0.9998 - val_loss: 0.0012 - val_iou_score: 0.9200\n",
      "Epoch 954/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 5.4820e-06 - iou_score: 0.9998 - val_loss: 0.0012 - val_iou_score: 0.9193\n",
      "Epoch 955/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.6705e-06 - iou_score: 0.9886 - val_loss: 0.0013 - val_iou_score: 0.9212\n",
      "Epoch 956/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.2223e-06 - iou_score: 0.9999 - val_loss: 0.0013 - val_iou_score: 0.9198\n",
      "Epoch 957/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.9674e-06 - iou_score: 0.9999 - val_loss: 0.0014 - val_iou_score: 0.9284\n",
      "Epoch 958/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 7.0104e-06 - iou_score: 0.9998 - val_loss: 0.0013 - val_iou_score: 0.9180\n",
      "Epoch 959/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 9.7723e-06 - iou_score: 0.9998 - val_loss: 0.0014 - val_iou_score: 0.9206\n",
      "Epoch 960/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 1.5468e-05 - iou_score: 0.9997 - val_loss: 0.0014 - val_iou_score: 0.9197\n",
      "Epoch 961/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 2.3228e-05 - iou_score: 0.9995 - val_loss: 0.0014 - val_iou_score: 0.9250\n",
      "Epoch 962/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 1.2456e-04 - iou_score: 0.9981 - val_loss: 0.0024 - val_iou_score: 0.9768\n",
      "Epoch 963/1400\n",
      "89/89 [==============================] - 22s 249ms/step - loss: 4.4536e-04 - iou_score: 0.9900 - val_loss: 0.0016 - val_iou_score: 0.9081\n",
      "Epoch 964/1400\n",
      "89/89 [==============================] - 22s 250ms/step - loss: 1.8190e-04 - iou_score: 0.9945 - val_loss: 0.0012 - val_iou_score: 0.9143\n",
      "Epoch 965/1400\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 3.9621e-05 - iou_score: 0.9986"
     ]
    }
   ],
   "source": [
    "history = model_utility.fit_model(x_train, y_train, model, batch_size = 10, epochs = int(epoch_num), validation_split = .13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 341ms/step - loss: 6.1736e-04 - iou_score: 0.0019\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/both2Aug_spoke_1200im_1400e_resnet34.h5\n"
     ]
    }
   ],
   "source": [
    "model_utility.save_model(f\"{model_path}{type}_spoke_{training_size}im_{epoch_num}e_{backbone}.h5\", model, history, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which model is this? - dark2Aug_spoke_360im_1400e_resnet34.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Train IOU Score:  0.9993763566017151\n",
      "Last Train Loss Score:  3.6315297620603815e-05\n",
      "Last Validation IOU Score:  0.968753457069397\n",
      "Last Validation Loss Score:  0.011049313470721245\n",
      "dark2Aug\n",
      "360\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "model_utility.display_results(f\"{model_path}{type}_spoke_{training_size}im_{epoch_num}e_{backbone}.json\")\n",
    "print(type)\n",
    "print(training_size)\n",
    "print(epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/\"\n",
    "type = \"dark2Aug\"\n",
    "training_size = \"360\"\n",
    "epoch_num = \"300\"\n",
    "backbone = \"resnet34\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dark2Aug\n",
      "360\n",
      "1400\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model(f\"models/{type}_spoke_{training_size}im_{epoch_num}e_{backbone}.h5\", compile = False)\n",
    "model.compile(optimizer = \"Adam\" , loss = \"binary_crossentropy\", metrics = [sm.metrics.IOUScore()], )\n",
    "\n",
    "print(type)\n",
    "print(training_size)\n",
    "print(epoch_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing with images outside of train/test(light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utility.model_testing(model, \"dark\", 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
